[{"url":"/2023/10/03/Java八股自总结：/","content":"\n\n# Java八股自总结：\n\n\n\n## 背景问题：\n\n#### 自我介绍：\n\n面试官，您好，我是四川大学计算机专业21级学生冉秀情，在校期间积累了坚实的编程基础，特别是在Java方面。我掌握Java语言的相关技术栈，与贵公司的岗位较为匹配，期待能加入贵公司，作为一名Java实习生，我会将我扎实的编程知识和团队合作精神应用到实际工作中，同时也希望通过这个机会，不断提升自己的技术。\n\n\n\n#### 实习时间 \n\n能够长期实习，课程不多，且与老师沟通过，不影响正常打卡上班\n\n#### 加入原因：\n\n1.看好贵公司的发展，同时贵公司的技术氛围和。。。的公司理念我很喜欢,如果能加入，会对我的技术和能力有很大提升\n\n## Java基础\n\n\n\n**String str = \"abc\" 和String str = new String(\"abc\")的区别**\n\n`String str =\"abc\"`的原理，采用字面值的方式创建时，`JVM`会先去字符串常量池中去查找是否存在\"abc\"这个对象，如果不存在就创建这个字符串，并把地址返回给`str`。如果存在则直接把\"abc\"这个字符串的地址返回给`str`。\n\n![img](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/16e1f7c1f13d9561tplv-t2oaga2asx-jj-mark3024000q75-1696302993864-1.webp)\n\n`String str = new String(\"abc\")`采用`new`关键字的方式创建，`JVM`也会去字符串常量池中查找有没有这个字符串，如果没有的话，就先在字符串常量池里创建\"abc\"这个字符串，然后再复制一份放在堆里并把地址返回给`str`。如果字符串常量池里存在该字符串，那么就直接复制一份放在堆里并把地址返回给`str`。\n\n![img](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/16e1f8c6aa324edetplv-t2oaga2asx-jj-mark3024000q75-1696303002110-3.webp)\n\n#### equals 的底层代码是什么?\n\n1. 先使用== 进行地址值的判断  \n2. 判断equals()中的值是否为字符串  \n3. 判断字符串的长度是否相同  \n4. 循环遍历进行判断两个字符串是否相同\n\n#### object中的hashcode()方法是做什么用的\n\n这是因为在一些容器（比如 `HashMap`、`HashSet`）中，有了 `hashCode()` 之后，判断元素是否在对应容器中的效率会更高（参考添加元素进`HashSet`的过程）！\n\n我们在前面也提到了添加元素进`HashSet`的过程，如果 `HashSet` 在对比的时候，同样的 `hashCode` 有多个对象，它会继续使用 `equals()` 来判断是否真的相同。也就是说 `hashCode` 帮助我们大大缩小了查找成本。\n\n##### **那为什么不只提供 `hashCode()` 方法呢？**\n\n这是因为两个对象的`hashCode` 值相等并不代表两个对象就相等。\n\n##### **那为什么两个对象有相同的 `hashCode` 值，它们也不一定是相等的？**\n\n因为 `hashCode()` 所使用的哈希算法也许刚好会让多个对象传回相同的哈希值。越糟糕的哈希算法越容易碰撞，但这也与数据值域分布的特性有关（所谓哈希碰撞也就是指的是不同的对象得到相同的 `hashCode` )。\n\n\n\n#### 为什么重写 equals() 时必须重写 hashCode() 方法？\n\n因为两个相等的对象的 `hashCode` 值必须是相等。也就是说如果 `equals` 方法判断两个对象是相等的，那这两个对象的 `hashCode` 值也要相等。\n\n如果重写 `equals()` 时没有重写 `hashCode()` 方法的话就可能会导致 `equals` 方法判断是相等的两个对象，`hashCode` 值却不相等。\n\n再map集合中，如果只重写equals方法，那么两个相同对象hashcode可能不同，会存在多个key相同的情况。\n\n\n\n#### **基本类型和包装类型的区别**\n\n##### 1.基本类型有初始值，而包装类型的默认值是null\n\n##### 2.包装类型可以为 null，而基本类型不可以\n\n数据库的查询结果可能是null，因为自动拆箱，用基本数据类型接收有[NPE](https://so.csdn.net/so/search?q=NPE&spm=1001.2101.3001.7020)（NullPointerException）风险。\n\n##### 3.存储位置有所区别：基本类型是成员变量就存储在[堆内存](https://so.csdn.net/so/search?q=堆内存&spm=1001.2101.3001.7020)里，如果是局部变量就存储在栈内存里；而包装类型则存储的是堆中的引用\n\n##### 4.包装类型可用于泛型，而基本类型不可以\n\n如果我们这么写\nList<int> a = new ArrayList<>();\n编译器会报错：Type argument cannot be of primitive type(类型参数不能为基本类型)\n这是为什么呢？因为泛型信息只存在于代码编译阶段，在进入 JVM 之前，与泛型相关的信息会被擦除掉，专业术语叫做类型擦除，最后只保留原始类型，而原始类型只能是 Object 类及其子类。\n\n##### 5.在使用“==”进行判断的时候的不同\n\n6. 自动装箱和自动拆箱\n把基本类型转换成包装类型的过程叫做装箱（boxing）。反之，把包装类型转换成基本类型的过程叫做拆箱（unboxing）。\n\n1）基本类型和包装类型进行 == 比较，包装类型会自动拆箱，直接和基本类型比较值\n\n```\nint a = 9;\nInteger b = 9;\nSystem.out.println(a == b);\n```\n\n\n上述代码的结果为 true。\n\n2）当需要进行自动装箱时，如果数字在 -128 至 127 之间，会直接使用缓存中的对象，而不是重新创建一个对象。\n这个知识我之前从未听闻，正是在写这篇文章的时候查看相关技术博客才了解到的，又学到了新知识！\n我们先来看这么一段代码：\n\n```\nInteger A = 199;  \nint a = A;  \n```\n\n执行第一句代码的时候，系统为我们执行了：\nInteger A = Integer.valueOf(199);\n执行第二句代码的时候，系统为我们执行了：\nint a = A.intValue();\n\n#### object类中的常用方法的用处：\n\n1、 getClass()：获取类的class对象。\n2、 hashCode:获取对象的hashCode值\n3、 equals():比较对象是否相等，比较的是值和地址，子类可重写以自定义。\n4、 clone()：克隆方法。\n5、 toString():如果没有重写，应用对象将打印的是地址值。\n6、 notify():随机选择一个在该对象上调用wait方法的线程，解除其阻塞状态。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。\n7、 notifyall():解除所有那些在该对象上调用wait方法的线程的阻塞状态。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。\n8、 wait():导致线程进入等待状态，直到它被其他线程通过notify()或者notifyAll唤醒。该方法只能在同步方法中调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。\n9、 finalize()：对象回收时调用\n\n#### 包装类的缓存\n\n![image-20231003111615708](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111615708.png)\n\n#### 数组和链表的不同\n\n|          | 数组                                                         | 链表                                                         |\n| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 逻辑结构 | （1）数组在内存中连续； (2)使用数组之前，必须事先固定数组长度，不支持动态改变数组大小；(3) 数组元素增加时，有可能会数组越界；(4) 数组元素减少时，会造成内存浪费；（5）数组增删时需要移动其它元素 | （1）链表采用动态内存分配的方式，在内存中不连续 (2)支持动态增加或者删除元素 |\n| 访问效率 | 数组在内存中顺序存储，可通过下标访问，访问效率高             | 链表访问效率低，如果想要访问某个元素，需要从头遍历           |\n| 越界问题 | 数组的大小是固定的，所以存在访问越界的风险                   | 只要可以申请得到链表空间，链表就无越界风险                   |\n| 使用场景 | 存储的大小变化不大，且可以事先确定大小，主要是进行查找，很少插入和删除时 | 长度变化较大时，事先无法估量数据规模，当线性表要求频繁插入和删除时 |\n\n\n\n#### 抽象类接口什么不同\n\n**抽象类**：在Java中被abstract关键字修饰的类称为抽象类，被abstract关键字修饰的方法称为抽象方法，抽象方法只有方法的声明，没有方法体。抽象类的特点：\n\na、抽象类不能被实例化只能被继承；\n\nb、包含抽象方法的一定是抽象类，但是抽象类不一定含有抽象方法；\n\nc、抽象类中的抽象方法的修饰符只能为public或者protected，默认为public；\n\nd、一个子类继承一个抽象类，则子类必须实现父类抽象方法，否则子类也必须定义为抽象类；\n\ne、抽象类可以包含属性、方法、构造方法，但是构造方法不能用于实例化，主要用途是被子类调用。\n\n***接口\\*：**Java中接口使用interface关键字修饰，特点为:\n\na、接口可以包含变量、方法；变量被隐士指定为public static final，方法被隐士指定为public abstract（JDK1.8之前）；\n\nb、接口支持多继承，即一个接口可以extends多个接口，间接的解决了Java中类的单继承问题；\n\nc、一个类可以实现多个接口；\n\n##### **相同点**\n\n（1）都不能被实例化 （2）接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。\n\n##### **不同点**\n\n（1）接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现。\n\n（2）实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。\n\n（3）接口强调特定功能的实现，而抽象类强调所属关系。\n\n#### **Java的基本类型的成员变量在栈还是堆？**\n\n- **第一种**: 在方法中声明的变量，即该变量是局部变量，每当程序调用方法时，系统都会为该方法建立一个方法栈，其所在方法中声明的变量就放在方法栈中，当方法结束系统会释放方法栈，其对应在该方法中声明的变量随着栈的销毁而结束，这就局部变量只能在方法中有效的原因\n\n  （1）当声明是基本类型的变量的时，其变量名及值（变量名及值是两个概念）是放在方法栈中\n\n  （2）当声明的是引用变量时，所声明的变量（该变量实际上是在方法中存储的是内存地址值）是放在方法的栈中，该变量所指向的对象是放在堆类存中的。\n\n  \n\n- **第二种** 在类中声明的变量是成员变量(全局变量),放在堆中\n\n  1. 声明的是基本类型的变量,其变量名及其值放在堆内存中\n  2. 声明的是引用类型时，其声明的变量仍然会存储一个内存地址值，该内存地址值指向所引用的对象。引用变量名和对应的对象仍然存储在相应的堆中。但与对象中的普通成员变量（局部变量）不同的是，它们的生命周期是在对象销毁时才结束的\n\n- **第三种** 静态变量：\n\n  ​\t静态变量随着类的加载而存在，是存储在方法区（Method Area）中的，而不是存储在栈或堆上，所以它的生命周期与程序的生命周期一样长。\n\n  ![img](./Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MjcxMjE2,size_16,color_FFFFFF,t_70.png)\n\n#### 浅拷贝和深拷贝的区别\n\n深拷贝和浅拷贝是只针对引用数据类型的\n\n![image-20231003111707252](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111707252.png)\n\n浅拷贝只复制指向某个对象的指针，而不复制对象本身，新旧对象还是共享同一块内存（分支）。\n\n浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。\n如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型），拷贝的就是内存地址 ，因此如果其中一个对象改变了这个地址，就会影响到另一个对象。\n\n深拷贝会另外创造一个一模一样的对象，新对象跟原对象不共享内存，修改新对象不会改到原对象，是“值”而不是“引用”（不是分支）\n\n拷贝第一层级的对象属性或数组元素\n递归拷贝所有层级的对象属性和数组元素\n深拷贝会拷贝所有的属性,并拷贝属性指向的动态分配的内存。当对象和它所引用的对象一起拷贝时即发生深拷贝。深拷贝相比于浅拷贝速度较慢并且花销较大。\n\n**引用拷贝**: 引用拷贝就是直接赋值，只在栈中创建一个新的引用，拷贝引用的地址，所以指向的是堆中同一个对象。\n\n**浅拷贝**：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象。\n\n**深拷贝**：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。\n\n\n\n![image-20231003111716166](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111716166.png)\n\n![image-20231003111721557](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111721557.png)\n\n#### 强引用、弱引用、软引用、虚引用的区别\n\n在Java中提供了四个级别的引用：**强引用**，**软引用**，**弱引用**和**虚引用**。在这四个引用类型中，只有强引用FinalReference类是包内可见，其他三种引用类型均为public，可以在应用程序中直接使用。引用类型的类结构如图所示。\n\n![image-20231003111728261](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111728261.png)\n\n##### **强引用**\n\nJava中默认声明的就是强引用，例如以下代码，如果M对象被回收了，会打印 finalize() 方法中的内容：\n\n```java\npublic class Demo {\n    public static void main(String[] args) throws IOException {\n        M m = new M();  //只要m还指向M对象，M对象就不会被回收\n        // m = null;   //手动置null\n        System.gc();  // 进行垃圾回收\n \n        System.in.read();\n    }\n}\n \nclass M {\n    @Override\n    protected void finalize() {\n        System.out.println(\"对象被回收了...\");\n    }\n}\n```\n\n运行结果：\n\n![img](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/v2-e5f1836efa6748c371bcd126823414f7_1440w-1696303052906-5.webp)\n\n\n\n只要强引用存在，垃圾收集器将永远不会回收被引用的对象，哪怕**内存不足**时，JVM也会直接抛出OutOfMemoryError，**不会去回收**。如果想中断强引用与对象之间的联系，可以显示的将强引用赋值为null，这样一来，JVM就可以适时的回收对象了。例如上面的代码，将 m = null; 注释放开时，运行结果如下：\n\n![image-20231003111738987](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111738987.png)\n\n\n\n##### 3、**软引用**\n\n软引用是用来描述一些非必需但仍有用的对象。在内存足够的时候，软引用对象不会被回收，只有在**内存不足**时，系统则**会回收**软引用对象，如果回收了软引用对象之后仍然没有足够的内存，才会抛出OutOfMemoryError。这种特性常常被用来实现**缓存技术**，比如网页缓存，图片缓存等。\n\n在 JDK1.2 之后，用 SoftReference 类来表示软引用。下面以一个例子来进一步说明强引用和软引用的区别。\n\n在运行下面的Java代码之前，需要先配置参数 -Xms2M -Xmx2M，将 JVM 的初始内存设为2M，最大可用内存为 2M。\n\n首先先来测试一下强引用，在限制了 JVM 内存的前提下，下面的代码运行正常\n\n```java\npublic class Demo {\n    public static void main(String[] args) {\n        // 当 new byte为 1M 时，程序运行正常\n        byte[] buff1 = new byte[1024 * 1024 * 1];\n        \n        // byte[] buff2 = new byte[1024 * 1024 * 1];\n    }\n}\n```\n\n但是如果我们再创建一个1M大小的 byte数组时，则内存不够使用，程序直接报错。因为强引用不会被回收。\n\n![image-20231003111745645](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111745645.png)\n\n\n\n接着来看一下软引用会有什么不一样，在下面的示例中先创建一个大小为 1M 的软引用对象，打印m的地址，然后进行垃圾回收，休眠500ms后打印m的地址。最后又创建了一个1M的字节数组，打印m的地址。\n\n```java\npublic class Demo {\n    public static void main(String[] args) {\n        SoftReference<byte[]> m = new SoftReference<>(new byte[1024 * 1024]);\n \n        System.out.println(m.get());\n        System.gc();\n        try {\n            Thread.sleep(500);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(m.get());\n        // 再分配一个数组，heap将装不下，\n        // 这时系统会进行垃圾回收，如果内存不够，会把软引用干掉\n        byte[] b = new byte[1024*1024*1];\n        System.out.println(m.get());\n    }\n}\n```\n\n运行结果：\n\n![img](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/v2-210fffb5827e8aea4115430e5b373238_1440w-1696303070608-7.webp)\n\n根据运行结果，我们可以看到，在内存不足的情况下，软引用才会被回收。\n\n\n\n##### 4、**弱引用**\n\n弱引用的引用强度比软引用要更弱一些，**无论内存是否足够**，只要 JVM 开始进行垃圾回收，那些被弱引用关联的对象**都会被回收**。在 JDK1.2 之后，用 WeakReference 来表示弱引用。\n\n我们以与软引用同样的方式来测试一下弱引用：\n\n```java\npublic class Demo {\n    public static void main(String[] args) {\n        WeakReference<byte[]> m = new WeakReference<>(new byte[1024 * 1024]);\n \n        System.out.println(m.get());\n        System.gc();\n        try {\n            Thread.sleep(500);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(m.get());\n    }\n}\n```\n\n运行结果：\n\n![image-20231003111756526](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111756526.png)\n\n根据运行结果，可以发现垃圾回收后被弱引用关联的对象被回收了。\n\n在 Java 集合中有一种特殊的 Map 类型：**WeakHashMap**， 在这种 Map 中存放了键对象的弱引用，当一个键对象被垃圾回收，那么相应的值对象的引用会从 Map 中删除。WeakHashMap 能够节约存储空间，可用来缓存那些非必须存在的数据。\n\n\n\n##### 5、**虚引用**\n\n虚引用是最弱的一种引用关系，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，它随时可能会被回收。在 JDK1.2 之后，用 PhantomReference 类来表示，通过查看这个类的源码，发现它只有一个构造函数和一个 get() 方法，而且它的 get() 方法仅仅是返回一个null，也就是说将永远无法通过虚引用来获取对象。虚引用必须要和 ReferenceQueue 引用队列一起使用。\n\n```java\npublic class PhantomReference<T> extends Reference<T> {\n    public T get() {\n        return null;\n    }\n \n    public PhantomReference(T referent, ReferenceQueue<? super T> q) {\n        super(referent, q);\n    }\n}\n\npublic class Demo {\n \n    private static final List<Object> LIST = new LinkedList<>();\n    private static final ReferenceQueue QUEUE = new ReferenceQueue();\n \n    public static void main(String[] args) {\n        PhantomReference<M> m = new PhantomReference<>(new M(), QUEUE);\n \n        new Thread(()->{\n            while (true) {\n                LIST.add(new byte[1024*1024]);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                    Thread.currentThread().interrupt();\n                }\n                System.out.println(m.get());\n            }\n        }).start();\n \n        new Thread(()->{\n            while (true) {\n                Reference poll = QUEUE.poll();\n                if(poll != null) {\n                    System.out.println(\"虚引用对象：\" + poll + \" 被jvm回收了\");\n                }\n            }\n        }).start();\n    }\n}\n \nclass M {\n    @Override\n    protected void finalize() {\n        System.out.println(\"对象被回收了...\");\n    }\n}\n```\n\n运行结果：\n\n![img](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/v2-db69836fc83d1e8d39f5088bc1a4b8a9_1440w-1696303085353-9.webp)\n\n当垃圾回收器准备回收一个对象时，如果发现它还有引用，那么就会在回收对象之前，把这个引用加入到与之关联的引用队列中去。主要用于**清理堆外内存**。\n\n#### Java运行一个程序的过程？\n\n\n\n#### 静态变量在什么阶段分配内存？\n\nStatic：\n\n- 加载：java虚拟机在加载类的过程中为静态变量分配内存。\n- 类变量：static变量在内存中只有一个，存放在方法区，属于类变量，被所有实例所共享\n- 销毁：类被卸载时，静态变量被销毁，并释放内存空间。static变量的生命周期取决于类的生命周期\n\n##### 序列化与反序列化\n\n首先，我认为，之所以需要序列化，核心目的是为了解决网络通信之间的对象传输问题。\n也就是说，如何把当前 JVM 进程里面的一个对象，跨网络传输到另外一个 JVM进程里面。\n而序列化，就是把内存里面的对象转化为字节流，以便用来实现存储或者传输。\n反序列化，就是根据从文件或者网络上获取到的对象的字节流，根据字节流里面保存的对象描述信息和状态。重新构建一个新的对象。\n\n![image-20231003111810871](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111810871.png)\n\n其次呢，序列化的前提是保证通信双方对于对象的可识别性，所以很多时候，我们会把对象先转化为通用的解析格式，比如 json、xml 等。然后再把他们转化为数据流进行网络传输，从而实现跨平台和跨语言的可识别性。\n\n#### Java反射有了解吗？举几个Java反射的应用案例\n\n反射是java语言的一个特性，它允程序在运行时（注意不是编译的时候），获取任意一个类的成员变量、成员方法和属性,调用任意一个对象的方法和属性,，这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。\n\n- 获取任意类的名称、package信息、所有属性、方法、注解、类型、类加载器等\n- 获取任意对象的属性，并且能改变对象的属性\n- 调用任意对象的方法\n- 判断任意一个对象所属的类\n- 实例化任意一个类的对象\n- 通过反射我们可以实现动态装配，降低代码的耦合度,动态代理等。\n\n##### 优点\n\n- 可以增加程序的灵活性，在运行过程中可以动态堆类进行修改和操作\n- 提高代码复用率，比如动态代理\n- 可以在运行是轻松获取任意一个类的方法、属性、并且还能通过反射进行动态调用\n\n##### 缺点\n\n- 使用反射后，可读性较差\n- 反射可以绕过一些限制访问的属性和方法，可能回导致一些安全性问题\n- 反射回设计动态类型的解析，所以JVM无法对这些代码进行优化，导致性能要比非反射调用更低\n\n##### 使用场景\n\n- AOP动态代理的场景中，使用动态生成的代理类来提升代码复用性。\n- IOC：用反射来实例化bean对象等\n\n\n\n#### String 、StringBuffer和StringBuilder的区别\n\n##### 1.可变性\n\n​\tString 内部的 value 值是 final 修饰的，所以它是不可变类。所以每次修改 String 的值，都会产生一个新的对象。\n​\tStringBuffer 和 StringBuilder 是可变类，字符串的变更不会产生新的对象。\n\n##### 2.线程安全性\n\n​\tString 是不可变类，所以它是线程安全的。\n​\tStringBuffer 是线程安全的，因为它每个操作方法都加了 synchronized 同步关键字。\n​\tStringBuilder 不是线程安全的。所以在多线程环境下对字符串进行操作，应该使用 StringBuffer，否则使用StringBuilder\n\n##### 3.性能方面。\n\n​\tString 的性能是最低的，因为不可变意味着在做字符串拼接和修改的时候，需要重新创建新的对象以及分配内存。\n​\t其次是 StringBuffer 要比 String 性能高，因为它的可变性使得字符串可以直接被修改\n​\t最后是 StringBuilder，它比 StringBuffer 的性能高，因为 StringBuffer 加了同步锁。\n\n##### 4.存储方面。\n\n​\tString 存储在字符串常量池里面\n​\tStringBuffer 和 StringBuilder 存储在堆内存空间。\n\n#### StringBuffer、StringBuilder的扩容原理\n\n扩容原理：\n\n`StringBuffer`的底层数组结构用的是`char`类型的数组如果没有指定大小，默认大小为16，指定了大小，默认大小为（16 + 指定大小）。\n\n所以，当我们使用`StringBuffer`对象的`append(...)`方法追加数据时，\n\n- 如果数组长度可以容纳追加的数据，就直接追加到数组\n- 如果char类型数组的长度无法容纳我们追加的数据，`StringBuffer`就会进行扩容。\n- 扩容时会用到`Arrays`类中的`copyOf(...)`方法，每次扩容的容量大小是原来的容量的2倍（通过无符号左移）加2。\n\n#### 说说ArrayList\n\nArrayList 是一个数组结构的存储容器，所以ArrayList是支持随机存取的，默认情况下，数组的长度是 10.当然我们也可以在构建 ArrayList 对象的时候自己指定初始长度。随着在程序里面不断的往 ArrayList 中添加数据，当添加的数据达到 10 个的时候，ArrayList 就没有多余容量可以存储后续的数据。这个时候 ArrayList 会自动触发扩容。扩容的具体流程很简单：\n1. 首先，创建一个新的数组，这个新数组的长度是原来数组长度的 1.5 倍。\n2. 然后使用 Arrays.copyOf 方法把老数组里面的数据拷贝到新的数组里面。\n    扩容完成后再把当前要添加的元素加入到新的数组里面，从而完成动态扩容的过程。\n\n\n\n#### hash怎么扩容有了解吗？\n\n- HashMap的底层是采用数组来存储数据，当 HashMap 中元素个数超过（大于）临界值时会自动触发扩容，这个临界值有一个计算公式。\n- threashold=loadFactor*capacity。loadFactor 的默认值是 0.75，capacity 的默认值是 16。当元素个数超过临界值就会触发Hash扩容（resize函数），默认扩容的大小是原来数组长度的 2 倍，HashMap 的最大容量是Integer.MAX_VALUE，也就是 2 的 31 次方-1。\n- 然后会进行数据迁移，会伴随着一次重新 hash 分配（reHash),是非常耗时的，并且会遍历 hash 表中所有的元素，HasMap让容量为2的幂次方，就是方便数据迁移，元素的位置是  元素的hash&（n - 1），此时n是全为1的二进制数，那么元素根据hash值的的位置要么不变，要么加上原来的长度, 底层的行为都是给 table 赋值一个两倍长度的新数组。\n\n#### 为什么扩容因子是 0.75？\n\n扩容因子表示 Hash 表中元素的填充程度，扩容因子的值越大，那么触发扩容的元素个数更多，\n虽然空间利用率比较高，但是 hash 冲突的概率会增加。\n扩容因子的值越小，触发扩容的元素个数就越少，也意味着 hash 冲突的概率减少，\n但是对内存空间的浪费就比较多，而且还会增加扩容的频率。\n因此，扩容因子的值的设置，本质上就是在 冲突的概率 以及 空间利用率之间的平衡。\n0.75 这个值的来源，和统计学里面的泊松分布有关。\n\n当扩容因子在 0.75 的时候，链表长度达到 8 的可能性几乎为 0，也就是比较好的达到了空间成本和时间成本的平衡。\n\n#### HashMap的Hash值如何计算\n\n **h = (key.hashCode ()) ^ (key.hashCode()>>16)**,让hashCode的高16位和低16位进行异或，这样可以让hash值得散列度更高，尽可能区减少hash冲突的情况，从而去提升数据查找性能。\n\n#### HashMap怎么解决hash冲突的\n\n首先，HashMap 底层采用了数组的结构来存储数据元素，数组的默认长度是 16，当我们通过 put 方法添加数据的时候，HashMap 根据 Key 的 hash 值进行取模运算,最终保存到数组的指定位置。\n但是这种设计会存在 hash 冲突问题，也就是两个不同 hash 值的 key，最终取模后会落到同一个数组下标。所以 HashMap 引入了链式寻址法来解决 hash 冲突问题， 对于存在冲突的key，HashMap 把这些 key 组成一个单向链表。然后采用尾插法把这个 key 保存到链表的尾部。另外，为了避免链表过长的问题，当链表长度大于 8 并且数组长度大于等于 64 的时候，HashMap 会把链表转化为红黑树,从而减少链表数据查询的时间复杂度问题，提升查询性能\n\n解决 hash 冲突问题的方法有很多，比如\n\n- 再 hash 法，就是如果某个 hash 函数产生了冲突，再用另外一个 hash 进行计算，\n- 开放寻址法，就是直接从冲突的数组位置往下寻找一个空的数组下标进行数据存储，(这个在 ThreadLocal 里面有使用到)。\n- 建立公共溢出区，也就是把存在冲突的 key 统一放在一个公共溢出区里面。\n\n#### HashMap在多线程情况下会产生哪些问题？会产生死锁吗？\n\n- JDK1.7 及之前版本的 `HashMap` 在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。\n- 为了解决这个问题，JDK1.8 版本的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 `HashMap`，因为多线程下使用 `HashMap` 还是会存在数据覆盖的问题。并发环境下，推荐使用 `ConcurrentHashMap` 。\n\n##### 例子\n\n- 两个线程 1,2 同时进行 put 操作，并且发生了哈希冲突（hash 函数计算出的插入下标是相同的）。\n\n  不同的线程可能在不同的时间片获得 CPU 执行的机会，当前线程 1 执行完哈希冲突判断后，由于时间片耗尽挂起。线程 2 先完成了插入操作。\n\n  随后，线程 1 获得时间片，由于之前已经进行过 hash 碰撞的判断，所有此时会直接进行插入，这就导致线程 2 插入的数据被线程 1 覆盖了。\n\n- 还有一种情况是这两个线程同时 `put` 操作导致 `size` 的值不正确，进而导致数据覆盖的问题：\n\n  1. 线程 1 执行 `if(++size > threshold)` 判断时，假设获得 `size` 的值为 10，由于时间片耗尽挂起。\n  2. 线程 2 也执行 `if(++size > threshold)` 判断，获得 `size` 的值也为 10，并将元素插入到该桶位中，并将 `size` 的值更新为 11。\n  3. 随后，线程 1 获得时间片，它也将元素放入桶位中，并将 size 的值更新为 11。\n  4. 线程 1、2 都执行了一次 `put` 操作，但是 `size` 的值只增加了 1，也就导致实际上只有一个元素被添加到了 `HashMap` 中。\n\n#### 说一说HashMap get元素的完整流程\n\n先计算key的hashcode值，然后计算key的hash值，通过（n - 1） & hash 找到对应的桶的位置。\n\n- 如果位置上没有结点，直接返回null。\n\n- 有结点，，判断头结点的hash值是否等于key的hash值\n\n  - hash值相等，继续用 “==” 和equals（）判断key是否相等，相等就返回\n\n  - hash值不相等，遍历整个链表或者红黑树结点，还是判断hash值和key是否相等\n\n  - 头结点hash值 < 0, 说明map正在扩容，需要到新的table中用一个 find() 方法去查找\n\n    \n\n#### 说一说HashMap put元素的完整流程\n\n1. 根据key的hashcode 获得hash值（hashcode ^ (hashcode  >>> 16)）\n2. 通过hash & (n - 1) 找到对应桶的位置\n3. 如果桶为空，就直接put\n4. 如果桶不为空就遍历桶中所有元素，通过比较hashcode --> \"==\"判断 -->equals 判断是否已存在，存在就更新value值， 不存在，就插入，size++     判断是否需要转化为红黑树      是否需要扩容\n\n#### ConcurrentHashMap为什么能保证线程安全？\n\n添加元素时首先会判断容器是否为空，\n\n- 如果为空则使用 volatile 加 CAS 来初始化，防止多个线程同时初始化，造成并发问题，\n\n- 如果容器不为空，则根据存储的元素计算该位置是否为空。\n\n  - 如果根据存储的元素计算结果桶为空，则利用 CAS 设置该节点，避免并发冲突；\n\n  - 如果根据存储的元素计算桶为空不为空，则使用 synchronized 锁住这个桶链表的头结点，然后，遍历桶中的数据，根据hash值与key，更新或新增节点到桶中，\n  - 如果桶中头结点的hash值为 MOVED（-1），就说明map正在进行扩容，此时会锁住这个桶中的链表来帮助扩容，避免扩容的并发问题，等待扩容完成再put入新的table\n\n  - 最后再判断是否需要转为红黑树。这样就能保证并发访问时的线程安全了。\n\n设置多个累加单元来计算size()的值，防止并发下计数错误。\n\n- 当线程竞争不激烈时，直接采用 CAS 对baseCount操作实现元素个数的原子递增。\n- 如果线程竞争激烈，使用一个数组来维护元素个数，如果要增加总的元素个数，则直接从数组中随机选择一个，再通过 CAS 实现原子递增，之后遍历数组中所有的值与baseCount累加。它的核心思想是引入了数组来实现对并发更新的负载。\n\n\n\n总结： ConcurrentHashMap 通过**对数组头结点加锁**和**加CAS的初始化**来保证线程安全的。\n\n\n\n#### 为什么 ConcurrentHashMap 不允许插入 null值？\n\n`ConcurrentHashMap` 的 key 和 value 不能为 null 主要是为了避免二义性。null 是一个特殊的值，表示没有对象或没有引用。（如果你用 null 作为键，那么你就无法区分这个键是否存在于 `ConcurrentHashMap` 中，还是根本没有这个键。）同样，如果你用 null 作为值，那么你就无法区分这个值是否是真正存储`ConcurrentHashMap` 中的，还是因为找不到对应的键而返回的。\n\n拿 get 方法取值来说，返回的结果为 null 存在两种情况：\n\n- 值没有在集合中 ；\n- 值本身就是 null。\n\n这也就是二义性的由来。\n\n多线程环境下，存在一个线程操作该 `ConcurrentHashMap` 时，其他的线程将该 `ConcurrentHashMap` 修改的情况，所以无法通过 `containsKey(key)` 来判断否存在这个键值对，也就没办法解决二义性问题了。\n\n与此形成对比的是，`HashMap` 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个。如果传入 null 作为参数，就会返回 hash 值为 0 的位置的值。HashMap 的设计是给单线程使用的，所以如果取到 null（空） 值，我们可以通过HashMap 的 containsKey(key)方 法来区分这个 null（空） 值到底是插入值是 null（空），还是本就没有才返回的 null（空） 值。单线程环境下，不存在一个线程操作该 HashMap 时，其他的线程将该 `HashMap` 修改的情况，所以可以通过 `contains(key)`来做判断是否存在这个键值对，从而做相应的处理，也就不存在二义性问题。\n\n\n也就是说，多线程下无法正确判定键值对是否存在（存在其他线程修改的情况），单线程是可以的（不存在其他线程修改的情况）。\n\n如果你确实需要在 ConcurrentHashMap 中使用 null 的话，可以使用一个特殊的静态空对象来代替 null。\n\n```java\npublic static final Object NULL = new Object();\n```\n\n举个例子，现在有线程 T1 调用了 ConcurrentHashMap 的 containsKey(key) 方法，\n我们期望返回的结果是 false，也就是说，T1 并没有往 ConcurrentHashMap 中 put null（空）值。\n但是，恰恰出了个意外，在线程 T1 还没有得到返回结果之前，线程 T2 又调用了\nConcurrentHashMap 的 put() 方法，插入了一个 Key，并且存入的 Value 是 null（空） 值。那么，线程 T1 最终得到的返回结果就变成 true 了。\n\n#### JDK新特性\n\n##### **JDK1.8的新特性:、**\n\n1. stream流\n\n   ```\n   List<String> strings = Arrays.asList(\"abc\", \"def\", \"gkh\", \"abc\");\n       //返回符合条件的stream\n       Stream<String> stringStream = strings.stream().filter(s -> \"abc\".equals(s));\n       //计算流符合条件的流的数量\n       long count = stringStream.count();\n   \n       //forEach遍历->打印元素\n       strings.stream().forEach(System.out::println);\n   \n   ```\n\n2、Lambda 表达式\n在Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8提供了更简洁的语法，lambda表达式：\n\n```text\nCollections.sort(names, (String a, String b) -> {\nreturn b.compareTo(a);\n});\n```\n\n3、函数式接口\n\nLambda表达式是如何在java的类型系统中表示的呢？每一个lambda表达式都对应一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的lambda表达式都会被匹配到这个抽象方法。因为 默认方法 不算抽象方法，所以你也可以给你的函数式接口添加默认方法。\n\n4、方法与构造函数引用\n\nJava 8 允许你使用 :: 关键字来传递方法或者构造函数引用，上面的代码展示了如何引用一个静态方法，我们也可以引用一个对象的方法：\n\n```text\nconverter = something::startsWith;\nString converted = converter.convert(\"Java\");\nSystem.out.println(converted);\n```\n\n5. 日期 Date-timeAPI\n\n- 增强了时区处理\n- 增强各种格式化、和时间计算\n\n##### JDK9新特性\n\n1. JShell，为 Java 提供了类似于 Python 的实时命令行交互工具。\n\n   ![image-20231003111847441](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111847441.png)\n\n2. String 改为用byte[]存储。\n\n##### jdk10新特性\n\n**局部变量类型推断(var)*****\n\n```\nvar id =0;\nvar codefx =newURL(\"https://mp.weixin.qq.com/\");\nvar list =newArrayList<>();\nvar list =List.of(1,2,3);\n```\n\n##### JDK11新特性\n\n##### String增强\n\n增加了一系列的字符串处理方法：\n\n```java\n//判断字符串是否为空\n\" \".isBlank();//true\n//去除字符串首尾空格\n\" Java \".strip();// \"Java\"\n//去除字符串首部空格\n\" Java \".stripLeading();   // \"Java \"\n//去除字符串尾部空格\n\" Java \".stripTrailing();  // \" Java\"\n//重复字符串多少次\n\"Java\".repeat(3);             // \"JavaJavaJava\"\n//返回由行终止符分隔的字符串集合。\n\"A\\nB\\nC\".lines().count();    // 3\n\"A\\nB\\nC\".lines().collect(Collectors.toList());\n```\n\n\n\n## MySQL：\n\n#### SQL语句执行顺序\n\n1. from 子句组装来自不同数据源的数据；\n\n2. where 子句基于指定的条件对记录行进行筛选；  \n\n3. group by 子句将数据划分为多个分组；  \n\n4. 使用聚集函数进行计算； \n\n5. 使用 having 子句筛选分组；\n\n6.  计算所有的表达式后，select；  \n\n7. 使用 order by 对结果集进行排序。\n\n8. limit限制查询数量、查询偏移量\n\n   ![image-20231003111856990](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111856990.png)\n\n#### 事务的四大特性（ACID）：\n\n- 原子性：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。\n- 一致性：事务完成时，必须使得所有的数据保持一致状态\n- 隔离性：数据库系统提供的隔离机制，保证事务不受外部并发操作的影响，在独立的环境下运行。\n- 持久性：事务一单提交或回滚，会对数据库产生永久的改变\n\n而对于这四大特性，实际上分为两个部分。 其中的原子性、一致性、持久化，实际上是由InnoDB中的两份日志来保证的，\n\n一份是redo log日志，一份是undo log日志。 而持久性是通过数据库的锁，加上MVCC来保证的。\n\n#### 并发事务问题：\n\n1. 脏读：一个事务读到了另一个事务还没有提交的数据。![image-20231003111916626](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111916626.png)\n\n   \n\n2. 不可重复读：一个事务先后读取同一条记录，但是两次读取的数据不同\n\n![image-20231003111926058](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111926058.png)\n\n3. 幻读：一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了”幻影“;![image-20231003111932452](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111932452.png)\n\n#### 事务隔离级别\n\n![image-20231003111936844](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111936844.png)\n\n####  mysql执行流程\n\n\n\n\n\n\n\n#### B+Tree 与 B-Tree相比\n\n- 所有的数据都会出现在叶子节点。\n- 叶子节点形成一个双向循环链表。\n- 非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的。![image-20231003111941842](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111941842.png)\n\n#### 为什么InnoDB存储引擎选择使用B+tree索引结构?\n\n1. 相对于二叉树，层级更少，搜索效率高；\n2.  对于B-tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储的键值减少，指针跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低；\n3. 相对Hash索引，B+tree支持范围匹配及排序操作；\n4. 数据都在叶子节点，搜索效率稳定，且叶子节点形成双向循环链表，便于范围查找和排序\n\n#### 聚集索引&二级索引\n\n![image-20231003111945629](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111945629.png)\n\n聚集索引选取规则:\n\n- ​\t如果存在主键，主键索引就是聚集索引。\n\n- ​\t如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。\n\n- ​\t如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引。\n\n  ![image-20231003111949312](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003111949312.png)\n\n- 聚集索引的叶子节点下挂的是这一行的数据 。\n- 二级索引的叶子节点下挂的是该字段值对应的主键值。\n\n#### 索引失效情况\n\n1. 在索引列上进行运算操作， 索引将失效  \t`explain select * from tb_user where substring(phone,10,2) = '15';` \n2. 字符串不加引号  `explain select * from tb_user where profession = 软件工程 and age = 31 and status = 0;`\n3. 模糊查询（尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效） `explain select * from tb_user where profession like '软件%';`\n4. or连接条件 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。\n5. 如果索引了多列（联合索引），要遵守最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳跃某一列，索引将会部分失效(后面的字段索引失效)。最左前缀法则中指的最左边的列，是指在查询时，联合索引的最左边的字段(即是第一个字段)必须存在，与我们编写SQL时，条件编写的先后顺序无关。\n6. 联合索引中，出现范围查询(>,<)，范围查询右侧的列索引失效。当范围查询使用>= 或 <= 时，走联合索引，不会使右侧的列索引失效\n7. MySQL评估不走索引比走索引还快，索引也失效。\n\n#### 如何去合理地创建表的索引\n\n- 针对于数据量较大，且查询比较频繁的表建立索引。\n\n- 针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引。\n- 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。\n- 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。\n- 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率。\n- 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增删改的效率\n\n#### 通过索引查询数据，会经历几次磁盘IO\n\n这个要根据B+树的高度和查询的条件来判断\n\n如果查询建立了聚集索引，或者能够使用覆盖索引，就不需要回表，也就是需要B+树的层高次，\n\n否则要查两次索引，也就是两倍层高次\n\n#### SQL优化\n\n##### 插入数据优化\n\n1. 批量插入数据 `Insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry'); `\n\n2. 手动控制事务 ，避免频繁开启、提交事务\n\n   `start transaction;\n   insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry');\n   insert into tb_test values(4,'Tom'),(5,'Cat'),(6,'Jerry');\n   insert into tb_test values(7,'Tom'),(8,'Cat'),(9,'Jerry');\n   commit;`\n\n3. 主键顺序插入，性能要高于乱序插入，乱序插入会出现页分裂会降低效率。\n\n4. 一次性需要插入大批量数据(比如: 几百万的记录)，使用insert语句插入性能较低，可以使用MySQL数据库提供的load指令进行插入\n\n   `-- 客户端连接服务端时，加上参数 -–local-infile`\n   `mysql –-local-infile -u root -p`\n   `-- 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关`\n   `set global local_infile = 1;`\n   `-- 执行load指令将准备好的数据，加载到表结构中`\n   `load data local infile '/root/sql1.log' into table tb_user fields terminated by ',' lines terminated by '\\n' ;`\n\n##### 主键优化\n\n- 满足业务需求的情况下，尽量降低主键的长度。\n- 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键。\n- 尽量不要使用UUID做主键或者是其他自然主键，如身份证号。\n- 业务操作时，避免对主键的修改\n\n##### order by优化\n\n- 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则。\n- 尽量使用覆盖索引。\n- 多字段排序, 一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC/DESC）。\n- 如果不可避免的出现filesort，大数据量排序时，可以适当增大排序缓冲区大小sort_buffer_size(默认256k)。\n\n##### group by优化\n\n-  在分组操作时，可以通过索引来提高效率。\n- 分组操作时，索引的使用也是满足最左前缀法则的。\n\n##### 表连接优化\n\nleft join的情况下，对右表加索引，左表是驱动表，左连接就是左边都要查出来，所以左边还是all，但是右边是ref了。\n\n左连接的时候索引应该加在右表，右连接应该加在左表。\n\n##### 子查询怎么优化\n\n把子查询转化为表连接，建立索引实现优化\n\n##### (limit优化)深度分页怎么优化？\n\n优化思路: 一般分页查询时，通过创建 覆盖索引 能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化\n\n先通过聚集索引查询主键，再利用覆盖索引来获取。\n\n`select * from tb_sku limit 2000000, 10;` \n\n可以转换为：`explain select * from tb_sku t , (select id from tb_sku order by id limit 2000000,10) a where t.id = a.id;`\n\n如果id或者其他有索引的字段是自增的，可以先通过索引找到偏移位置，再分页：\n\nselect * from test_big_data where name like 'itlgitlg%' and id > 800000 order by id asc limit 0,10\n\n##### count优化\n\ncount(数字)：InoDB 引擎遍历整张表，但不取值。服务层对于返回的每一行，放一个数字“1”进去，直接按行进行累加。\n\ncount(*)： InnoDB引擎并不会把全部字段取出来，而是专门做了优化，不取值，服务层直接按行进行累加。\n\n按照效率排序的话，count(字段) < count(主键 id) < count(1) ≈ count(*)，所以尽量使用 count(*)。\n\n##### update优化\n\nInnoDB的行锁是针对索引加的锁，不是针对记录加的锁 ,并且该索引不能失效，否则会从行锁升级为表锁 。\n\n\n\n#### 慢sql怎么看 怎么解决\n\n慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有SQL语句的日志。如果要开启慢查询日志，需要在MySQL的配置文件（/etc/my.cnf）中配置如下信息：\n\n```\n# 开启MySQL慢日志查询开关`\n`slow_query_log=1`\n\n`#设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志`\n`long_query_time=2`\n```\n\n```\n#重启mysql服务\n`systemctl restart mysqld` \n```\n\n检查慢查询日志 ：在慢查询日志中，只会记录执行时间超多我们预设时间（2s）的SQL，执行较快的SQL是不会记录的。\n\n那这样，通过慢查询日志，就可以定位出执行效率比较低的SQL，从而有针对性的进行优化\n\n**用explain分析sql**\n\n##### explain中的字段：\n\n[explain有哪些字段，分别有什么含义_explain字段含义-CSDN博客](https://blog.csdn.net/weixin_50998273/article/details/111938295#:~:text=explain有哪些字段，分别有什么含义 1 1. id SQL查询中的序列号。 id列数字越大越先执行，如果说数字一样大，那么就从上往下依次执行。 2 2.,查询真正使用到的索引。 ... 8 8. key_len 查询用到的索引长度（字节数）。 ... 更多项目)\n\n解决：\n\n1. SQL语句优化，尽量精简，去除非必要语句\n2. 索引优化，让所有SQL都能够走索引\n3. 如果是表的瓶颈问题，则分表，单表数据量维持在2000W（理论上）以内\n4. 如果是单库瓶颈问题，则分库，读写分离\n5. 如果是物理机器性能问题，则分多个数据库节点\n\n#### 怎么保证redis和DB的数据一致性\n\n##### 采用延时双删\n\n先删除缓存，再更新数据库，当更新数据后休眠一段时间通过定时任务（可通过整合定时任务框架、创建线程池，从中拿出一个线程休眠一段时间再启动）再删除一次缓存。\n\n##### 异步更新缓存(基于订阅binlog的同步机制)\n\n采用缓存淘汰策略，先更新数据库，再删除对应redis缓存后更新缓存。\n\n![image-20231003112001061](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112001061.png)\n\n通过 Canal（消息推送工具也可以用kafka、rabbitMQ等来实现可靠性消息通信更新Redis。） 组件，（伪装成从节点）监控 Mysql 中 binlog（记录MySQL中新的写入、更新、删除等操作） 的日志，把更新后的数据同步到 Redis 里面，canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。。\n\n![image-20231003112007121](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112007121.png)\n\n因为这里是基于最终一致性来实现的，如果业务场景不能接受数据的短期不一致性，那就不能使用这个方案来做。\n\n#### union和union all的区别\n\n对于union查询，就是把多次查询的结果合并起来，形成一个新的查询结果集。\n对于联合查询的多张表的列数必须保持一致，字段类型也需要保持一致。\nunion all 会将全部的数据直接合并在一起，union 会对合并之后的数据去重。\n\n#### 使用自增id还是UUID来当主键\n\nUUID。B+树使用双向链表来保存数据，所以使用自增id能够直接加到尾部，不需要页分裂，效率很高，且占用的空间小。但是如果一些敏感信息设置成自增就很容易被推理，暴露机密。\n\n同时当单表的数据量上来之后我们就需要进行水平分表操作（将一张数据表的数据分成多张表），如果这时我们还是按照之前的自增形式来做主键 id，就有可能会出现 id 重复的问题。\n\n如果使用UUID，生成的ID不仅是表独立的，而且是库独立的。对以后的数据操作很有好处，可以说一劳永逸。我们可以使用 UUID 来作为不重复的主键 id，但是 UUID 是无序的字符串，所以主键索引就会失效，而且占用空间大。\n\n- 全局唯一性：不能出现重复的 id\n- 递增性：MySQL 的 InnoDB 使用的是聚簇索引，由于多数 RDBMS 使用 B-tree 的数据结构来存储索引数据，因此在主键的选择上我们还是应该尽可能地使用有序的主键来保证写入性能，我们保证下一个 id 一定大于上一个 id，以此来满足事务版本号、IM 增量消息或者排序的特殊需求\n- 安全性：如果 id 是连续的，那么我们在知道一些基本规则的情况下就能很轻松地推测出下一份数据，这在一些机密性较高的业务场景是很危险的。所以我们有时会希望 id 是无规则的，最好还能包含有时间戳，这样就能够在开发中快速了解这个分布式 id 的生成时间\n- 高性能高可用性：确保在任何时候都能正确地生成 id，并且在高并发的环境下也能表现良好\n\n\n\nUUID：我们可以使用 UUID 来作为不重复的主键 id，但是 UUID 是无序的字符串，所以主键索引就会失效\n\n优点：简单、方便、性能好、出现数据拆分、合并存储的时候，能达到全局的唯一性\n缺点：占用空间大，无序性、存储的是字符串、查询效率低、传输数据量大\n\n雪花算法：雪花算法是 Twitter 推出的针对分布式环境下的 id 生成算法，其结果是一个 Long 型的 64bit id。具体实现上使用 41bit 作为毫秒数，10bit 作为机器的 id（5bit 是数据中心，5bit 是机器 id），12bit 作为毫秒内的流水号（这意味着每个节点在每毫秒内可以产生 4096 个 id），最后还有一个符号位永远是 0\n\n优点：不依赖数据库、完全在内存中生成 id、高性能高可用、容量大、每秒可生成数百万个 id、id 递增、后续插入数据库的索引时性能较高\n缺点：严重依赖系统时钟，如果某台机器的系统时钟发生回拨，就有可能会造成 id 冲突甚至 id 乱序\n\n#### 讲一讲mysql主从部署\n\n##### 概述\n\n主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。\n\nMySQL 复制的优点主要包含以下三个方面：\n主库出现问题，可以快速切换到从库提供服务。\n实现读写分离，降低主库的访问压力。\n可以在从库中执行备份，以避免备份期间影响主库服务。\n\n##### 原理 \n\nMySQL主从复制的核心就是 二进制日志，具体的过程如下：\n\n![image-20231003112012277](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112012277.png)\n\n从上图来看，复制分成三步：\n1. Master 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。\n2. 从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 。\n3. slave重做中继日志中的事件，将改变反映它自己的数据。\n\n##### 搭建主从环境：\n\n配置主库，修改配置文件 /etc/my.cnf\n\n```\n#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 232-1，默认为1\nserver-id=1\n#是否只读,1 代表只读, 0 代表读写\nread-only=0\n```\n\n重启MySQL服务器\n\n```\nsystemctl restart mysqld \n```\n\n登录mysql，创建远程连接的账号，并授予主从复制权限\n\n```\n#创建itcast用户，并设置密码，该用户可在任意主机连接该MySQL服务\nCREATE USER 'itcast'@'%' IDENTIFIED WITH mysql_native_password BY 'Root@123456'\n;\n#为 'itcast'@'%' 用户分配主从复制权限\nGRANT REPLICATION SLAVE ON *.* TO 'itcast'@'%';\n```\n\n通过指令，查看二进制日志坐标\n\n```\nshow master status ;\n```\n\n![image-20231003112018880](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112018880.png)\n\n字段含义说明：\nfile : 从哪个日志文件开始推送日志文件\nposition ： 从哪个位置开始推送日志\nbinlog_ignore_db : 指定不需要同步的数据库\n\n##### 从库配置\n\n修改配置文件 /etc/my.cnf\n\n```\n#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，和主库不一样即可\nserver-id=2\n#是否只读,1 代表只读, 0 代表读写\nread-only=1\n```\n\n重新启动MySQL服务\n\n```\nsystemctl restart mysqld\n```\n\n登录mysql，设置主库配置\n\n```\nCHANGE REPLICATION SOURCE TO SOURCE_HOST='192.168.200.200', SOURCE_USER='itcast',\nSOURCE_PASSWORD='Root@123456', SOURCE_LOG_FILE='binlog.000004',\nSOURCE_LOG_POS=663;\n或者\nCHANGE MASTER TO MASTER_HOST='192.168.200.200', MASTER_USER='itcast',\nMASTER_PASSWORD='Root@123456', MASTER_LOG_FILE='binlog.000004',\nMASTER_LOG_POS=663;\n```\n\n开启同步操作\n\n```\nstart replica ; #8.0.22之后\nstart slave ; #8.0.22之前\n```\n\n查看主从同步状态\n\n```\nshow replica status ; #8.0.22之后\nshow slave status ; #8.0.22之前\n```\n\n![image-20231003112023725](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112023725.png)\n\n#### mysql：死锁是什么？ 实习中你有遇到死锁的情况吗\n\n简单来说就是两个或者两个以上的线程在执行的过程中，争夺同一个共享资源造成的相互等待的现象。如果没有外部干预，线程会一直阻塞无法往下执行，这些一直处于相互等待资源的线程就称为死锁线程。\n\n解决方法：尽量使用相同的顺序来访问索引记录和表，可以实现对数据排序，保证每个线程按照固定的顺序来处理。\n\n#### MySQL三大范式\n\n- ##### 第一范式（1 NF）：字段不可再拆分。\n\n  ![image-20231003112028615](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112028615.png)\n\n- ##### 第二范式（2 NF）：表中任意一个主键或任意一组联合主键，可以确定除该主键外的所有的非主键值。\n\n  1. 造成整表的数据冗余。\n\n  如，学生表，可能我就只有2个学生，每个学生都有许多的信息，比如，年龄、性别、身高、住址......如果与课程信息放到同一张表中，可能每个学生有3门课程，那数据总条数就会变成6条了。但是通过拆分，学生表我们只需要存储 2 条学生信息，课程表只需要存储 3 条课程信息，成绩表就只需保留学号、课程名称和成绩字段。\n\n  2. 更新数据不方便。\n\n  假设，课程的学分发生了变更，那我们就需要把整表关于该课程的学分都要更新一次，但如果我们拆分出课程表，那我们就只需要把课程表中的课程信息更新就行。\n\n  3. 插入数据不方便或产生异常。\n\n  ① 假设主键是学号或课程名称，我们新增了某个课程，需要把数据插入到表中，这时，可能只有部分人有选修这门课程，那我们插入数据的时候还要规定给哪些人插入对应的课程信息，同时可能由于成绩还没有，我们需要对成绩置空，后续有成绩后还得重新更新一遍。\n\n  ② 假设主键是学号和课程名称的联合主键。同样也是新增了某课程，但是暂时没有人选修这门课，缺少了学号主键字段数据，会导致课程信息无法插入。\n\n- ##### 第三范式（3 NF）：在任一主键都可以确定所有非主键字段值的情况下，不能存在某非主键字段 A 可以获取 某非主键字段 B。\n\n\n#### undo log\n\n- 回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : 提供回滚(保证事务的原子性) 和MVCC(多版本并发控制) 。\n- undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undolog中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。\n- Undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于MVCC。\n\n#### redo log\n\n该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo logfile）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中, 用于在刷新脏页到磁盘,发生错误时, 进行数据恢复使用。\n\n![image-20231003112038852](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112038852.png)\n\n有了redolog之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redolog buffer中。在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据恢复，这样就保证了事务的持久性。 而如果脏页成功刷新到磁盘 或 或者涉及到的数据已经落盘，此时redolog就没有作用了，就可以删除了，所以存在的两个redolog文件是循环写的。\n\n\n\n#### MySQL如何解决幻读\n\n**快照读**\n\n快照读，读取的是**快照数据**，不加锁的普通 SELECT 都属于快照读。\n\n```sql\nsql\n复制代码SELECT * FROM table WHERE ...\n```\n\n通过mvcc机制来解决幻读\n\n**当前读**\n\n当前读就是读的是**最新数据**，而不是历史的数据，加锁的 SELECT，或者对数据进行增删改都会进行当前读。\n\n```sql\nsql复制代码SELECT * FROM table LOCK IN SHARE MODE;\nSELECT FROM table FOR UPDATE;\nINSERT INTO table values ...\nDELETE FROM table WHERE ...\nUPDATE table SET ...\n```\n\n在当前读的条件下，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。\n\n- 索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 。\n- 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。\n- 索引上的范围查询(唯一索引)--会访问到不满足条件的第一个值为止。\n\n*间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会*\n*阻止另一个事务在同一间隙上采用间隙锁。*\n\n\n\n[MySQL 如何解决幻读（MVCC 原理分析） - 掘金 (juejin.cn)](https://juejin.cn/post/7056583607929798692)\n\n#### \n\n\n\n#### MVCC机制\n\n详见[看一遍就理解：MVCC原理详解 - 掘金 (juejin.cn)](https://juejin.cn/post/7016165148020703246#heading-24)\n\n\n\nInnoDB还会自动的给我们添加三个隐藏字段及其含义分别是\n\n![image-20231003112043284](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112043284.png)\n\n全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，快照读为MySQL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undo log日志、readView。\n\n\n\n当某个事务执行第一条修改语句时，会记录undo log日志，记录数据变更之前的样子; 然后更新记录，\n并且记录本次操作的事务ID，回滚指针，回滚指针用来指定如果发生回滚，回滚到哪一个版本。\n\n![image-20231003112046405](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112046405.png)\n\n\n\n最终我们发现，不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条\n记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录。\n\nReadView（读视图）是快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id。\n\n**RC隔离级别下，在事务中每一次执行快照读时生成ReadView。**\n\n**RR隔离级别下，仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView**\n\nReadView中包含了四个核心字段：\n\n![image-20231003112049869](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112049869.png)\n\n而在readview中就规定了版本链数据的访问规则：\ntrx_id 代表当前undolog版本链对应事务ID。\n\n![image-20231003112052634](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112052634.png)\n\n\n\n#### MySQL 事务的可重复读和读已提交，Read View 时机\n\n- READ COMMITTED ：在事务中每一次执行快照读时生成ReadView。\n- REPEATABLE READ：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。\n\n\n\n#### 乐观锁与悲观锁，在MySQL中怎么实现\n\n悲观锁，比较消极的一种锁处理方式。直接在操作数据时，抢占锁。其他的事务在进行时就会等待，直到占有锁的事务释放锁为止。\n\n​    这种处理方式能保证数据的最大一致性，但是容易导致锁超时、并发程度低等问题。 首先我们开启事务一，并且对id=1的数据进行update操作，此时我们不提交事务。\n\n```\nmysql root@127.0.0.1:demo> begin;\nQuery OK, 0 rows affected\nTime: 0.002s\nmysql root@127.0.0.1:demo> update `user` set name = '张三111111'where id = 1;\nQuery OK, 1 row affected\nTime: 0.004s\n```\n\n​    接着我们开启事务二，对id=1的数据进行update操作，查看此时会发生什么情况？\n\n```\nmysql root@127.0.0.1:demo> begin;\nQuery OK, 0 rows affected\nTime: 0.002s\nmysql root@127.0.0.1:demo> update `user` set sex = 1 where id = 1;\n```\n\n​    我们执行完update语句之后，就处于等待状态，SQL语句也不会马上被执行，这是因为事务一没有commit，也就没有释放id=1的数据对应的写锁。\n\n\n\n乐观锁认为数据一般情况下不会造成冲突，只有当数据去执行修改情况时，才会针对数据冲突做处理。这里是如何发现冲突了呢？常规的方式，都是在数据行上加一个版本号或者时间戳等字段。(本文使用version作为版本好方式，使用时间戳方式同理)\n\n​    **乐观锁的实现原理：**\n\n- 一个事务在读取数据时，将对应的版本号字段读取出来，假设此时的版本号是1。    \n- 另外一个事务也是执行同样的读取操作。当事务一提交时，对版本号执行+1，此时该数据行的版本号就是2。    \n- 第二个事务执行修改操作时，针对业务数据做条件，并默认增加一个版本号作为where条件。此时修改语句中的版本号字段是不满足where条件，该事务执行失败。通过这种方式来达到锁的功能。\n\n\n\n- 聚簇索引和非聚簇索引\n- 覆盖索引是什么\n- 联合索引是什么\n- 联合索引在b+树中怎么存储\n- where a = xxx and b > xxx and c = xxx，联合索引(a,b,c)，会用到哪些索引\n- SQL优化，使用索引的时候怎么优化\n- SQL优化，使用表连接的时候怎么优化\n- SQL优化，子查询怎么优化，答得用表连接代替子查询\n- SQL优化，分页查询怎么优化，不会。。。忘了\n- 使用update更新一个大表，怎么优化，答了一下条件查询字段尽量走索引，然后就不知道了。\n\n\n\n## 常用框架\n\n### spring\n\n#### BeanFactory和 FactoryBean 的区别\n\nBeanFactory：**Spring IoC容器的顶级对象**，BeanFactory被翻译为“Bean⼯⼚”，在Spring的IoC容器中，“Bean⼯⼚”**负责创建Bean对象**。BeanFactory是⼯⼚。\n\nFactoryBean：它是⼀个Bean，是⼀个能够**辅助Spring实例化其它Bean对象**的⼀个**工厂Bean**。\n在Spring中，Bean可以分为两类：\n\n- 第⼀类：普通Bean\n- 第⼆类：⼯⼚Bean（记住：⼯⼚Bean也是⼀种Bean，只不过这种Bean⽐较特殊，它可以辅助Spring实例化其它Bean对象。）\n\n\n\n#### Bean 的作用域有哪些?\n\n- **singleton** : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。\n- **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。\n- **request** （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。\n- **session** （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。\n- **application/global-session** （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。\n- **websocket** （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。\n\n\n\n#### Bean 是线程安全的吗？\n\nSpring 框架中的 Bean 是否线程安全，取决于其作用域和状态。\n\nprototype 作用域下，每次获取都会创建一个新的 bean 实例，不存在资源竞争问题，所以不存在线程安全问题。\n\nsingleton 作用域下，IoC 容器中只有唯一的 bean 实例，可能会存在资源竞争问题（取决于 Bean 是否有状态）。如果这个 bean 是有状态的话，那就存在线程安全问题（有状态 Bean 是指包含可变的成员变量的对象）。\n\n不过，大部分 Bean 实际都是无状态（没有定义可变的成员变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。\n\n对于有状态单例 Bean 的线程安全问题，常见的有两种解决办法：\n\n1. 在 Bean 中尽量避免定义可变的成员变量。\n2. 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在 `ThreadLocal` 中（推荐的一种方式）\n\n\n\n#### bean生命周期（只针对单例的bean，如果是多例，只负责到第八步）\n\n1. **Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化**(Bean的无参构造方法)\n\n2. **Bean实例化后对将Bean的引入和值注入到Bean的属性中**（通过set方法给Bean属性赋值）\n\n3. 检查Bean是否实现了Aware相关的接口，调用接口中的方法\n\n   ​\t当Bean实现了BeanNameAware，Spring会将Bean的名字传递给Bean。\n   ​\t当Bean实现了BeanClassLoaderAware，Spring会将加载该Bean的类加载器传递给Bean。\n   ​\t当Bean实现了BeanFactoryAware，Spring会将Bean⼯⼚对象传递给Bean。\n\n4. **如果有配置BeanPostProcessor类，并且重写before（），执行这个before方法**\n\n5. 如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。\n\n6. **配置⽂件中的init-method指定初始化⽅法，init方法初始化bean**\n\n7. **如果有配置BeanPostProcessor类，并且重写after（），执行这个after方法**\n\n8. **此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。**\n\n9. 如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法.\n\n10. **spring容器关闭，配置⽂件中destroy-method指定销毁⽅法。最后销毁bean**\n\n![image-20231003112059255](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112059255.png)\n\n\n\n#### @Resource 和 @Autowired注解的区别\n\n@Resource注解也可以完成⾮简单类型注⼊。那它和@Autowired注解有什么区别？\n@Resource注解是JDK扩展包中的，也就是说属于JDK的⼀部分。所以该注解是标准注解，更加具\n有通⽤性。(JSR-250标准中制定的注解类型。JSR是Java规范提案。)\n@Autowired注解是Spring框架⾃⼰的。\n***@Resource注解默认根据名称装配byName，未指定name时，使⽤属性名作为name。通过name***\n***找不到的话会⾃动启动通过类型byType装配。***\n***@Autowired注解默认根据类型装配byType，如果想根据名称装配，需要配合@Qualifier注解⼀起***\n***⽤。***\n@Resource注解⽤在属性上、setter⽅法上。\n@Autowired注解⽤在属性上、setter⽅法上、构造⽅法上、构造⽅法参数上\n\n#### spring如何解决循环依赖问题\n\n[浅谈 Spring 如何解决 Bean 的循环依赖问题 - 掘金 (juejin.cn)](https://juejin.cn/post/7218080360403615804)\n\nSpring为什么可以解决**set + singleton**模式下循环依赖？\n**根本的原因在于：这种⽅式可以做到将“实例化Bean”和“给Bean属性赋值”这两个动作分开去完成**。\n实例化Bean的时候：调⽤⽆参数构造⽅法来完成。此时可以先不给属性赋值，可以**提前**将该**Bean对象“曝光**”给外界。\n给Bean属性赋值的时候：调⽤set⽅法来完成。\n两个步骤是完全可以分离开去完成的，并且这两步不要求在同⼀个时间点上完成。\n也就是说，Bean都是单例的，我们可以**先把所有的单例Bean实例化**出来，放到⼀个集合当中（我们可以称之为缓存），所有的单例Bean全部实例化完成之后，以后我们**再慢慢的调⽤setter⽅法给属性赋值**，这样就解决了循环依赖的问题。\n\n原理是spring的三级缓存\n\n三级缓存分为：\n\n- 一级缓存（`singletonObjects`）：缓存的是**已经实例化、属性注入、初始化后**的 Bean 对象，key存储bean名称，\n  value存储Bean对象。\n- 二级缓存（`earlySingletonObjects`）：缓存的是**实例化后，但未属性注入、初始化**的 Bean对象（用于提前暴露 Bean），key存储bean名称，value存储早期的Bean对象。\n- 三级缓存（`singletonFactories`）：缓存的是一个 `ObjectFactory`对象，主要作用是生成原始对象进行 AOP 操作后的**代理对象**，key存储bean名称，value存储该Bean对应的ObjectFactory对象。\n\n这三个缓存其实本质上是三个Map集合，spring会先从⼀级缓存中获取Bean，如果获取不到，则从⼆级缓存中获取Bean，如果⼆级缓存还是获取不到，则从三级缓存中获取之前曝光的ObjectFactory对象，通过ObjectFactory对象获取Bean实例，这样就解决了循环依赖的问题。\n\n\n\n#### Spring的IOC\n\n##### IOC提出背景\n\n- 代码书写现状:耦合度太高，我们修改一处代码，往往要修改很多出相关联的代码。\n\n解决方法：我们在创建对象的时候，不自己创建而是由外部提供对象\n\n##### **IOC的核心概念**\n\n**IoC（Inversion of Control:控制反转）** 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理，IOC容器负责对象的创建、初始化等一系列工作，被创建或被管理的对象在IOC容器中统称为Bean。\n\n##### **为什么叫控制反转？**\n\n- **控制**：指的是对象创建（实例化、管理）的权力\n- **反转**：控制权交给外部环境（Spring 框架、IoC 容器）\n\n在实际项目中一个 Service 类可能依赖了很多其他的类，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。\n\n##### IOC的实现方式\n\nDI-依赖注入\n在容器中建立bean与bean之间的依赖关系的整个过程叫做依赖注入\n下方当中的业务层中代码想要正常运行还需要Book bookDao的实现,那么的话IOC把这种依赖关系也提供给业务层，这个过程叫依赖注入。那么这个注入指的就是属性的注入\n\n![image-20231003112104377](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112104377.png)\n\n\n\n#### **JDK和CGLib动态代理区别**\n\n##### JDK动态代理具体实现原理：\n\nJDK动态代理只能代理接口，Spring通过Java的反射机制生产被代理接口的新的匿名实现类，通过invoke方法来增强方法，重写了其中AOP的增强方法。\n\n##### CGLib动态代理：\n\n既可以代理接⼝，⼜可以代理类，通过修改代理对象类的字节码生成子类（也就是代理类）来处理，底层是通过继承的⽅式实现的，所以代理类不能被final修饰。性能⽐JDK动态代理要好。 \n\n##### 使用注意：\n\n如果要被代理的对象是个实现类（有对应接口），那么Spring会使用JDK动态代理来完成操作（Spirng默认采用JDK动态代理实现机制）；\n\n如果要被代理的对象不是个实现类（没有代理接口），那么Spring会强制使用CGLib来实现动态代理。\n\n\n\n#### AOP实际应用场景，好处，spring中如何实现？\n\nAOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任(交叉业务)（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。\n\nSpring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 **JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 **Cglib** 生成一个被代理对象的子类来作为代理，如下图所示：\n\n![image-20231003112107747](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112107747.png)\n\n\n\n⼀般⼀个系统当中都会有⼀些系统服务，例如：⽇志、事务管理、安全等。这些系统服务被称为：交叉业务\n这些交叉业务⼏乎是通⽤的，不管你是做银⾏账户转账，还是删除⽤户数据。⽇志、事务管理、安全，这些都是需要做的。\n如果在每⼀个业务处理过程当中，都掺杂这些交叉业务代码进去的话，存在两⽅⾯问题：\n\n- 第⼀：交叉业务代码在多个业务流程中反复出现，显然这个交叉业务代码没有得到复⽤。并且修改这些交叉业务代码的话，需要修改多处。\n- 第⼆：程序员⽆法专注核⼼业务代码的编写，在编写核⼼业务代码的同时还需要处理这些交叉业务。\n\n使⽤AOP可以很轻松的解决以上问题。\n\n![image-20231003112111175](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112111175.png)\n\n⽤⼀句话总结AOP：将与核⼼业务⽆关的代码独⽴的抽取出来，形成⼀个独⽴的组件，然后以横向交叉\n的⽅式应⽤到业务流程当中的过程被称为AOP。\nAOP的优点：\n第⼀：代码复⽤性增强。\n第⼆：代码易维护。\n第三：使开发者更关注业务逻辑。\n\n\n\n\n\n#### Spring事务以及对应的传播机制。\n\n##### Spring 管理事务的方式有几种？\n\n- **编程式事务**：在代码中硬编码(不推荐使用) : 通过 `TransactionTemplate`或者 `TransactionManager` 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。\n- **声明式事务**：在 XML 配置文件中配置或者直接基于注解（推荐使用） : 实际是通过 AOP 实现（基于`@Transactional` 的全注解方式使用最多）\n\n##### 什么是事务的传播⾏为？\n\n在service类中有a()⽅法和b()⽅法，a()⽅法上有事务，b()⽅法上也有事务，当a()⽅法执⾏过程中调⽤了\nb()⽅法，事务是如何传递的？合并到⼀个事务⾥？还是开启⼀个新的事务？这就是事务传播⾏为。\n\n##### 一共有7种传播行为\n\n- REQUIRED：⽀持当前事务，如果不存在就新建⼀个(默认)【没有就新建，有就加⼊】 (a方法种如果有事务，b方法种还是使用原有的事务， a方法没有事务，b方法就开启新事务)\n- SUPPORTS：⽀持当前事务，如果当前没有事务，就以⾮事务⽅式执⾏【有就加⼊，没有就不管了】\n- MANDATORY： 必须运⾏在⼀个事务中，如果当前没有事务正在发⽣，将抛出⼀个异常【有就加⼊，没有就抛异常】\n- REQUIRES_NEW： 开启⼀个新的事务，如果⼀个事务已经存在，则将这个存在的事务挂起【不管有没有，直接开启⼀个新事务，开启的新事务和之前的事务不存在嵌套关系，之前事务被挂起】\n- NOT_SUPPORTED： 以⾮事务⽅式运⾏，如果有事务存在，挂起当前事务【不⽀持事务，存在就挂起】\n- NEVER： 以⾮事务⽅式运⾏，如果有事务存在，抛出异常【不⽀持事务，存在就抛异常】\n- NESTED： 如果当前正有⼀个事务在进⾏中，则该⽅法应当运⾏在⼀个嵌套式事务中。被嵌套的事务可以独⽴于外层事务进⾏提交或回滚。如果外层事务不存在，⾏为就像REQUIRED⼀样。【有事务的话，就在这个事务⾥再嵌套⼀个完全独⽴的事务，嵌套的事务可以独⽴的提交和回滚。没有事务就和 REQUIRED⼀样。 \n\n##### 事务超时\n\n```\n@Transactional(timeout = 10) \n```\n\n以上代码表示设置事务的超时时间为10秒。\n表示超过10秒如果该事务中所有的DML语句还没有执⾏完毕的话，最终结果会选择回滚。\n默认值-1，表示没有时间限制。\n这⾥有个坑，事务的超时时间指的是哪段时间？\n在当前事务当中，最后⼀条DML语句执⾏之前的时间。如果最后⼀条DML语句后⾯很有很多业务逻辑，\n这些业务代码执⾏的时间不被计⼊超时时间。\n\n\n\n#### Spring 框架中用到了哪些设计模式？\n\n**工厂设计模式** : Spring 使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。\n\n**代理设计模式** : Spring AOP 功能的实现。\n\n**单例设计模式** : Spring 中的 Bean 默认都是单例的。\n\n\n\n**模板方法模式** : Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。\n\n**包装器设计模式** : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。\n\n**观察者模式:** Spring 事件驱动模型就是观察者模式很经典的一个应用。\n\n**适配器模式** : Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配`Controller`\n\n\n\n\n\n### Mybatis\n\n#### mybatis #{} ${} 为什么还要保留${}\n\n\n\n### SpringBoot\n\n#### springBoot启动流程\n\n## redis\n\n#### redis为什么更快？\n\n- Redis 基于内存，内存的访问速度是磁盘的上千倍；\n- Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用（Redis 线程模式后面会详细介绍到）；\n- Redis 内置了多种优化过后的数据结构实现，性能非常高。\n\n#### 为什么要用 Redis/为什么要用缓存？\n\n**高性能**\n\n假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。\n\n**高并发**\n\n一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 Redis 的情况，Redis 集群的话会更高）。\n\n> QPS（Query Per Second）：服务器每秒可以执行的查询次数；\n\n由此可见，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。\n\n#### Redis 常用的数据结构有哪些\n\n- **5 种基础数据结构**：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。\n- **3 种特殊数据结构**：HyperLogLogs（基数统计）、Bitmap （位存储）、Geospatial (地理位置)。\n\n#### String 还是 Hash 存储对象数据更好呢？\n\n- String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。\n- String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。\n\n在绝大部分情况，我们建议使用 String 来存储对象数据即可！\n\n\n\n\n\n\n\n\n\n#### redis 怎么实现持久化的？\n\n#### 讲一讲redis主从部署，是从节点还是主节点主动？\n\n#### redis哨兵集群的作用\n\n#### 分布式锁了解吗？为什么要给分布式锁加ttl呢？\n\n应用程序遇到一些问题比如释放锁的逻辑突然挂掉，或者一个线程获得锁后Redis宕机，可能会导致锁无法被释放，进而造成共享资源无法再被其他线程/进程访问。为了避免锁无法被释放，我们可以想到的一个解决办法就是：**给这个 key（也就是锁） 设置一个过期时间** 。**一定要保证设置指定 key 的值和过期时间是一个原子操作！！！** 不然的话，可能会出现只获取锁但是还没有设置过期时间就宕机，依然可能会出现锁无法被释放的问题。\n\n#### redis分布锁有哪些 实现机制 setnx\n\n#### redis中字符串怎么表示的？\n\n#### 跳表结构（重要）\n\n#### Redis基本数据类型\n\n#### IO多路复用\n\n#### redis单线程在多核机器里使用会不会浪费机器资源？\n\n#### redis 执行命令还是单线程，那如何利用多核心来提升性能？\n\n可以在系统部署多个 redis docker 容器来处理，达到充分利用 cpu 多核心的效果\n\n####  redis缓存穿透、缓存击穿、缓存雪崩是什么？怎么解决？（重要）\n\n##### 什么是缓存穿透？\n\n缓存穿透说简单点就是大量请求的 key 是不合理的，**根本不存在于缓存中，也不存在于数据库中** 。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。\n\n- 首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端\n- 缓存空对象，如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下：`SET key value EX 10086` 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。\n- **布隆过滤器**\n\n我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**\n\n1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。\n2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。\n\n我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**\n\n1. 对给定元素再次进行相同的哈希计算；\n2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。\n\n\n\n##### 缓存击穿\n\n缓存击穿中，请求的 key 对应的是 **热点数据** ，该数据 **存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）** 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。\n\n- 设置热点数据永不过期或者过期时间比较长。\n- 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。\n- 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。\n\n##### 什么是缓存雪崩？\n\n缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。\n\n1. 过期时间可以设置随机数，如30+（0~5）分钟随机，不要同时过期，每个key的过期时间分散，让他们的过期时间尽量均匀分散开\n2. 给缓存业务添加降级限流策略\n\n3. 给业务添加多级缓存\n\n4. 使用redis集群（主从、哨兵、redis集群）提高可用性（redis宕机）\n\n5. 数据预热：数据预热的含义就是在正式部署之前，先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。\n\n\n\n\n#### zset底层用的什么数据结构，如何控制层高的.\n\n#### 项目用的Redis什么数据结构，key是什么，value是什么（String，访客数据）\n\n#### String能存多条数据吗？用什么存好（哈希或者set？）\n\n#### 哈希底层（忘了）\n\n\n\n\n\n\n\n## 计算机网络：\n\n#### OSI七层模型\n\n![image-20231003112121217](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112121217.png)\n\n1、物理层：实现计算机节点之间比特流的透明传输，规定传输媒体接口的标准，屏蔽掉具体传输介质和物理设备的差异，使数据链路层不必关心网络的具体传输介质，按照物理层规定的标准传输数据就行\n\n2、数据链路层：通过差错控制、流量控制等方法，使有差错的物理线路变为无差错的数据链路。\n\n数据链路层的几个基本方法：数据封装成桢、透明传输、差错控制、流量控制。\n\n封装成桢：把网络层数据报加头和尾，封装成帧，帧头中包括源MAC地址和目的MAC地址。\n透明传输：零比特填充、转义字符。\n差错控制：接收者检测错误,如果发现差错，丢弃该帧，差错控制方法有 CRC 循环冗余码\n流量控制：控制发送的传输速度，使得接收方来得及接收。传输层TCP也有流量控制功能，但TCP是端到端的流量控制，链路层是点到点（比如一个路由器到下一个路由器）\n3、网络层：**实现网络地址与物理地址的转换**，并通过**路由选择算法为分组通过通信子网选择最适当的路径**\n\n网络层最重要的一个功能就是：路由选择。路由一般包括路由表和路由算法两个方面。每个路由器都必须建立和维护自身的路由表，一种是静态维护，也就是人工设置，适用于小型网络；另一种就是动态维护，是在运行过程中根据网络情况自动地动态维护路由表。\n\n4、传输层：提供源端与目的端之间提供可靠的透明数据传输，传输层协议为不同主机上运行的进程提供逻辑通信。\n\n网络层协议负责的是提供主机间的逻辑通信；\n传输层协议负责的是提供进程间的逻辑通信。\n5、会话层：是用户**应用程序和网络之间的接口**，负责在网络中的**两节点之间建立、维持、终止通信**。\n\n6、表示层：**处理用户数据的表示问题**，如数据的编码、**格式转换、加密和解密、压缩和解压缩**。\n\n7、应用层：为**用户的应用进程提供网络通信服务**，完成和实现用户请求的各种服务。\n\n#### TCP和UDP的区别和应用场景\n\n- **是否面向连接**：UDP 在传送数据之前不需要先建立连接。而 TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。\n\n- **是否是可靠传输**：远地主机在收到 UDP 报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达。TCP 提供可靠的传输服务，TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。\n\n  \n\n- **是否有状态**：这个和上面的“是否可靠传输”相对应。TCP 传输是有状态的，这个有状态说的是 TCP 会去记录自己发送消息的状态比如消息是否发送了、是否被接收了等等。为此 ，TCP 需要维持复杂的连接状态表。而 UDP 是无状态服务，简单来说就是不管发出去之后的事情了\n\n- **传输效率**：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。\n\n- **传输形式**：TCP 是面向字节流（把应用程序交下来的数据看成无结构的字节流）的，UDP 是面向报文（对应用层的报文既不合并也不拆分，对长度大小都不做任何改变）的。\n\n- **首部开销**：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。\n\n- **是否提供广播或多播服务**：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多；\n\n##### TCP使用场景\n\n效率要求相对低，但对准确性要求相对高的场景。因为传输中需要对数据确认、重发、排序等操作，相比之下效率没有UDP高。举几个例子：文件传输（准确高要求高、但是速度可以相对慢）、接受邮件、远程登录。\n\n##### UDP使用场景\n\n效率要求相对高，对准确性要求相对低的场景。举几个例子：游戏、在线视频、网络语音电话（即时通讯，速度要求高，但是出现偶尔断续不是太大问题，并且此处完全不可以使用重发机制）、广播通信（广播、多播），即使出现传输错误也可以容忍。\n\n\n\n\n\n#### TCP三次握手四次挥手\n\n建立一个 TCP 连接需要“三次握手”，缺一不可：\n\n- **一次握手**:客户端发送带有 SYN（SEQ=x） 标志的数据包 -> 服务端，然后客户端进入 **SYN_SEND** 状态，等待服务器的确认；\n- **二次握手**:服务端发送带有 SYN+ACK(SEQ=y,ACK=x+1) 标志的数据包 –> 客户端,然后服务端进入 **SYN_RECV** 状态\n- **三次握手**:客户端发送带有 ACK(ACK=y+1) 标志的数据包 –> 服务端，然后客户端和服务器端都进入**ESTABLISHED** 状态，完成 TCP 三次握手。\n\n\n\n三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。\n\n1. **第一次握手**：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常\n2. **第二次握手**：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常\n3. **第三次握手**：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常\n\n三次握手就能确认双方收发功能都正常，缺一不可。\n\n![image-20231003112124898](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112124898.png)\n\n##### 第 2 次握手传回了 ACK，为什么还要传回 SYN？\n\n服务端传回发送端所发送的 ACK 是为了告诉客户端：“我接收到的信息确实就是你所发送的信号了”，这表明从客户端到服务端的通信是正常的。回传 SYN 则是为了建立并确认从服务端到客户端的通信也是正常的。\n\n> SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。\n\n\n\n![image-20231003112128868](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112128868.png)\n\n断开一个 TCP 连接则需要“四次挥手”，缺一不可：\n\n1. **第一次挥手**：客户端发送一个 FIN（SEQ=x） 标志的数据包->服务端，用来关闭客户端到服务器的数据传送。然后客户端进入 **FIN-WAIT-1** 状态。\n2. **第二次挥手**：服务器收到这个 FIN（SEQ=X） 标志的数据包，它发送一个 ACK （ACK=x+1）标志的数据包->客户端 。然后服务端进入 **CLOSE-WAIT** 状态，客户端进入 **FIN-WAIT-2** 状态。\n3. **第三次挥手**：服务端发送一个 FIN (SEQ=y)标志的数据包->客户端，请求关闭连接，然后服务端进入 **LAST-ACK** 状态。\n4. **第四次挥手**：客户端发送 ACK (ACK=y+1)标志的数据包->服务端，然后客户端进入**TIME-WAIT**状态，服务端在收到 ACK (ACK=y+1)标志的数据包后进入 CLOSE 状态。此时如果客户端等待 **2MSL** 后依然没有收到回复，就证明服务端已正常关闭，随后客户端也可以关闭连接了。\n\n**只要四次挥手没有结束，客户端和服务端就可以继续传输数据！**\n\n##### 为什么不能把服务器发送的 ACK 和 FIN 合并起来，变成三次挥手？\n\n因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复 ACK，表示接收到了断开连接的请求。等到数据发完之后再发 FIN，断开服务器到客户端的数据传送。\n\n##### [#](#如果第二次挥手时服务器的-ack-没有送达客户端-会怎样) 如果第二次挥手时服务器的 ACK 没有送达客户端，会怎样？\n\n客户端没有收到 ACK 确认，会重新发送 FIN 请求。\n\n##### [#](#为什么第四次挥手客户端需要等待-2-msl-报文段最长寿命-时间后才进入-closed-状态) 为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？\n\n第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN，如果客户端在 2*MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。\n\n> **MSL(Maximum Segment Lifetime)** : 一个片段在网络中最大的存活时间，2MSL 就是一个发送和一个回复所需的最大时间。如果直到 2MSL，Client 都没有再次收到 FIN，那么 Client 推断 ACK 已经被成功接收，则结束 TCP 连接。\n\n\n\n\n\n#### TCP的可靠传输是如何保障的\n\n**基于数据块传输**：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。\n\n**连接稳定可靠**：通过三次握手四次挥手，保证了连接的可靠性。\n\n**序号机制，对失序数据包重新排序以及去重**：TCP 为了保证不发生丢包，就给每个包一个序列号（序列号是数据第一个字节的序号），有了序列号能够将接收到的数据**根据序列号排序**，并且**去掉重复序列号的数据**就可以实现数据包去重。\n\n**校验和** : TCP添加伪首部，TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。\n\n**超时重传** : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个**相应的确认信息**（ACK）。**超过该定时器时间依旧未收到对方确认，那么对应的数据包就被假设为已丢失并进行重传，便会重新发送该数据**\n\n**流量控制** : **接收方根据自己接收缓冲的大小，可在设置确认报文字段的窗口字段，动态调整发送发发送窗口大小。**TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。\n\n**拥塞控制** : 当网络拥塞时（发送方的数据迟迟无法到达接收方），发送方估算网络拥堵程度减少数据的发送。\n\nTCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制\n\n![image-20231003112134508](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112134508.png)\n\n![image-20231003112139329](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112139329.png)\n\nudp第四个字段为17\n\n#### Http状态码\n\n\n\n##### 2XX 成功\n\n200 ok（请求成功）\n204 no content （请求成功，但是没有结果返回）\n206 partial content （客户端请求一部分资源，服务端成功响应，返回一范围资源）\n\n##### 3XX 重定向\n\n301 move permanently （永久性重定向）\n302 found （临时性重定向）\n303 see other （示由于请求对应的资源存在着另一个 URI，应使用 GET方法定向获取请求的资源）\n304 not modified （表示在客户端采用带条件的访问某资源时，服务端找到了资源，但是这个请求的条件不符合。跟重定向无关）\n307 temporary redirect （跟302一个意思）\n\n##### 4XX 客户端错误\n\n400 bad request （请求报文存在语法错误）\n401 unauthorized （需要认证（第一次返回）或者认证失败（第二次返回））\n403 forbidden （请求被服务器拒绝了）\n404 not found （服务器上无法找到请求的资源）\n\n##### 5XX 服务器错误\n\n500 internal server error （服务端执行请求时发生了错误）\n503 service unavailable （服务器正在超负载或者停机维护，无法处理请求）\n\n\n\n\n#### Get和Post的区别\n\nGET 和 POST 是 HTTP 协议中两种常用的请求方法，它们在不同的场景和目的下有不同的特点和用法。一般来说，可以从以下几个方面来区分二者\n\n- 语义（主要区别）：GET 通常用于获取或查询资源，而 POST 通常用于创建或修改资源。\n- 幂等：GET 请求是幂等的，即多次重复执行不会改变资源的状态，而 POST 请求是不幂等的，即每次执行可能会产生不同的结果或影响资源的状态。\n- 格式：GET 请求的参数通常放在 URL 中，形成查询字符串（querystring），而 POST 请求的参数通常放在请求体（body）中，可以有多种编码格式，如 application/x-www-form-urlencoded、multipart/form-data、application/json 等。GET 请求的 URL 长度受到浏览器和服务器的限制，而 POST 请求的 body 大小则没有明确的限制。不过，实际上 GET 请求也可以用 body 传输数据，只是并不推荐这样做，因为这样可能会导致一些兼容性或者语义上的问题。\n- 缓存：由于 GET 请求是幂等的，它可以被浏览器或其他中间节点（如代理、网关）缓存起来，以提高性能和效率。而 POST 请求则不适合被缓存，因为它可能有副作用，每次执行可能需要实时的响应。\n- 安全性：GET 请求和 POST 请求如果使用 HTTP 协议的话，那都不安全，因为 HTTP 协议本身是明文传输的，必须使用 HTTPS 协议来加密传输数据。另外，GET 请求相比 POST 请求更容易泄露敏感数据，因为 GET 请求的参数通常放在 URL 中。\n\n\n\n#### **讲述浏览器中输入一个网址之后背后的过程：**\n\n1. URL 解析：\n\n   **地址解析**：首先判断你输入的是一个合法的 URL 还是一个待搜索的关键词，（如果是关键词就直接按照关键词搜索）并且根据你输入的内容进行自动完成、字符编码等操作。\n\n   **HSTS**：由于安全隐患，会使用 HSTS 强制客户端使用 HTTPS 访问页面。详见：[你所不知道的 HSTS](https://link.zhihu.com/?target=https%3A//www.barretlee.com/blog/2015/10/22/hsts-intro/)。\n\n   **其他操作**：浏览器还会进行一些额外的操作，比如安全检查、访问限制（之前国产浏览器限制 996.icu）。\n\n2. DNS 查询\n\n   **1**.**浏览器缓存**：浏览器会先检查是否在缓存中，没有则调用系统库函数进行查询。\n\n   **2. 操作系统缓存**：操作系统也有自己的 DNS缓存，但在这之前，会向检查域名是否存在本地的 Hosts 文件里，没有则向 DNS 服务器发送查询请求。\n\n   **3. 路由器缓存**：路由器也有自己的缓存。\n\n   **4. 本地 DNS 缓存**：ISP DNS 就是在客户端电脑上设置的首选 DNS 服务器，也就是本地DNS服务器，它们在大多数情况下都会有缓存。\n\n   **5.根域名服务器查询**：本地 DNS 服务器会将请求转发到互联网上的根域,再查询顶级域名服务器，权威域名服务器，找到对应服务器的ip地址\n\n3. 通过ip地址找到服务器，并与服务器建立TCP 连接\n\n4. 浏览器向web服务器发送一个HTTP请求\n\n5. 服务器对发送的请求进行处理，并发回一个HTML响应\n\n6. 浏览器接收到来自服务器的响应资源后，会对资源进行分析接受响应，浏览器渲染页面，得到我们看到的网页\n\n#### 一个请求达到后端整个过程\n\n1. **建立连接**：客户端通过TCP/IP协议与服务器建立连接，这是HTTP的基础。\n2. **发送请求**：客户端向服务器发送一个HTTP请求，其中包含请求方法（例如GET或POST）和要访问的资源的URL。\n3. **处理请求**：服务器接收到请求后，会解析请求，查找所请求的资源，并准备好将其发送回客户端的响应。\n4. **发送响应**：服务器将响应发送回客户端，响应通常包括状态码、响应头和响应体。\n5. **关闭连接**：连接在请求和响应之后通常会被关闭，但HTTP/1.1引入了持久连接以改善性能。\n\n\n\n\n\n\n\n#### 讲讲TCP的表头有哪些字段，这些字段你是背的还是了解过有什么作用，有过对每个字段的功能的测试吗\n\n![image-20231003112148772](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112148772.png)\n\n1. 源端口和目的端口       各占2个字节，分别写入源端口和目的端口。\n\n2. 序号 在一个TCP连接中传送的字节流中的每一个字节都按照顺序编号，本字段表示本报文段所发送数据的第一个字节的序号。\n\n3. 确认号 起到收到对方下一个报文段的第一个数据字节的序号。若确认号为N，则证明到序号N-1为止的所有数据都已正确收到。\n\n4. 数据偏移（TCP首部长度） TCP报文段的数据起始处距离TCP报文段的起始处有多远，以4B为单位，即一个数值是4B\n\n5. 保留          占6位，保留为今后使用，但目前应置为0 。\n\n6.  当URG置为1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍然是普通数据。这时要与首部中紧急指针（Urgent Pointer）字段配合使用。\n\n7.  确认ACK（ACKnowledgment）      仅当ACK = 1时确认号字段才有效，当ACK = 0时确认号无效。TCP规定，在连接建立后所有的传送的报文段都必须把ACK置为1。\n\n8. 推送 PSH（PuSH）    当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应。在这种情况下，TCP就可以使用推送（push）操作。这时，发送方TCP把PSH置为1，并立即创建一个报文段发送出去。接收方TCP收到PSH=1的报文段，就尽快地（即“推送”向前）交付接收应用进程。而不用再等到整个缓存都填满了后再向上交付。\n\n9. 复位RST（ReSeT）       当RST=1时，表名TCP连接中出现了严重错误（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立传输连接。RST置为1还用来拒绝一个非法的报文段或拒绝打开一个连接。\n\n10.  同步SYN（SYNchronization）       在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1，因此SYN置为1就表示这是一个连接请求或连接接受报文。\n\n11.  终止FIN（FINis，意思是“完”“终”）          用来释放一个连接。当FIN=1时，表明此报文段的发送发的数据已发送完毕，并要求释放运输连接。\n\n12.  窗口             占2字节。窗口值是【0，2^16-1】之间的整数。窗口指的是发送本报文段的一方的接受窗口（而不是自己的发送窗口）。窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，窗口值作为接收方让发送方设置其发送窗口的依据。\n\n​    \n\n13. 检验和       占2字节。检验和字段检验的范围包括首部和数据这两部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。伪首部的格式和UDP用户数据报的伪首部一样。但应把伪首部第4个字段中的17改为6（TCP的协议号是6）；把第5字段中的UDP中的长度改为TCP长度。接收方收到此报文段后，仍要加上这个伪首部来计算检验和。若使用IPv6,则相应的伪首部也要改变。\n\n14. 紧急指针            占2字节。紧急指针仅在URG=1时才有意义，它指出本报文段中的紧急数据的字节数（紧急数据结束后就是普通数据） 。因此，在紧急指针指出了紧急数据的末尾在报文段中的位置。当所有紧急数据都处理完时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为0时也可以发送紧急数据。\n\n15.  选项       长度可变，最长可达4字节。当没有使用“选项”时，TCP的首部长度是20字节。\n\n\n\n#### http和tcp的区别，分别在哪一层\n\n**TCP协议是传输层协议**，主要解决数据如何在网络中传输，***而HTTP是应用层协议*****，主要解决如何包装数据，两者本质上没有可比性。\n\n我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET 等，也可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP 文本信息，然后使用TCP/IP做传输层协议将它发到网络上。\n\n**Http协议是建立在TCP协议基础之上的**，当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过TCP建立起一个到服务器的连接通道，当本次请求需要的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的，所以Http连接是一种短连接，是一种无状态的连接。\n\n说明：从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。\n\n\n\n**Http是无状态的短连接**，直观地说，就是每个请求都是独立的，与前面的请求和后面的请求都是没有直接联系的，因此加入了cookie、session等机制实现有状态的的web。**而TCP是有状态的长连接**\n\n\n\n\n\n\n\n\n####  tcp慢启动是怎么实现的\n\n最初的TCP的实现方式是，在连接建立成功后便会向网络中发送大尺寸的数据包，假如网络出现问题，很多这样的大包会积攒在路由器上，很容易导致网络中路由器缓存空间耗尽，从而发生拥塞。因此现在的TCP协议规定了，新建立的连接不能够一开始就发送大尺寸的数据包，而只能从一个小尺寸的包开始发送，在发送和数据被对方确认的过程中去计算对方的接收速度，来逐步增加每次发送的数据量（最后到达一个稳定的值，进入高速传输阶段。相应的，慢启动过程中，TCP通道处在低速传输阶段），以避免上述现象的发生。这个策略就是慢启动。\n\nTCP刚刚开始传输数据时，会**从一个较小的cwnd = 1开始，然后按照2的幂逐步增长到sshthresh的过程称为慢启动**，直到**cwnd（拥塞窗口）>（慢启动门限）ssthresh**，则**结束慢启动过程**，**进入到拥塞避免阶段**\n\n\n\n#### http和https有什么区别？\n\nhttp与https都是常用的网络通信协议\n\n**端口号**：HTTP 默认是 80，HTTPS 默认是 443。\n\n**URL 前缀**：HTTP 的 URL 前缀是 `http://`，HTTPS 的 URL 前缀是 `https://`。\n\n**安全性和资源消耗**：HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。\n\n**SEO（搜索引擎优化）**：搜索引擎通常会更青睐使用 HTTPS 协议的网站，因为 HTTPS 能够提供更高的安全性和用户隐私保护。使用 HTTPS 协议的网站在搜索结果中可能会被优先显示，从而对 SEO 产生影响。\n\n\n\n#### 说一说https实现加密通信的实现原理？\n\n- https是基于tcp协议的，首先客户端会和服务端发起链接建立\n- 服务端返回它的证书给客户端，证书中包含了服务端公钥S.pub、颁发机构和有效期等信息证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。\n- 客户端通过操作系统、浏览器内置的根证书（内部包含CA机构的公钥C.pub）验证证书的合法性\n- 客户端生成随机的对称加密密钥Z，然后通过服务端的公钥S.pub加密发送给服务端\n- 服务器通过私钥进行解密，获得客户端浏览器的对称加密密钥\n- 客户端和服务端之后就通过对称加密密钥Z加密数据来进行http通信\n\n\n\n网站在使用HTTPS前，需要向**CA机构**申领一份**数字证书**，数字证书里含有证书持有者信息、公钥信息等。服务器把证书传输给浏览器，浏览器从证书里获取公钥就行了，证书就如身份证，证明“该公钥对应该网站”。而这里又有一个显而易见的问题，“**证书本身的传输过程中，如何防止被篡改”**？即如何证明证书本身的真实性？身份证运用了一些防伪技术，而数字证书怎么防伪呢？解决这个问题我们就接近胜利了！\n\n##### **如何放防止数字证书被篡改？**\n\n我们把证书原本的内容生成一份“签名”，比对证书内容和签名是否一致就能判别是否被篡改。这就是数字证书的“防伪技术”，这里的“签名”就叫`数字签名`：\n\n##### **数字签名**\n\n这部分内容建议看下图并结合后面的文字理解，图中左侧是数字签名的制作过程，右侧是验证过程：\n\n![img](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/v2-7c78935389af46e197e96d9cd91c06dd_1440w-1696303314365-11.webp)\n\n数字签名的生成与验证（https://cheapsslsecurity.com/blog/digital-signature-vs-digital-certificate-the-difference-explained/）\n\n\n数字签名的制作过程：\n\n1. CA机构拥有非对称加密的私钥和公钥。\n2. CA机构对证书明文数据T进行hash。\n3. 对hash后的值用私钥加密，得到数字签名S。\n\n明文和数字签名共同组成了数字证书，这样一份数字证书就可以颁发给网站了。\n那浏览器拿到服务器传来的数字证书后，如何验证它是不是真的？（有没有被篡改、掉包）\n\n浏览器验证过程：\n\n1. 拿到证书，得到明文T，签名S。\n2. 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。\n3. 用证书里指明的hash算法对明文T进行hash得到T’。\n4. 显然通过以上步骤，T’应当等于S‘，除非明文或签名被篡改。所以此时比较S’是否等于T’，等于则表明证书可信。\n\n为何么这样可以保证证书可信呢？我们来仔细想一下。\n\n##### **中间人有可能篡改该证书吗？**\n\n假设中间人篡改了证书的原文，由于他没有CA机构的私钥，所以无法得到此时加密后签名，无法相应地篡改签名。浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书已被篡改，证书不可信，从而终止向服务器传输信息，防止信息泄露给中间人。\n\n既然不可能篡改，那整个证书被掉包呢？\n\n##### **中间人有可能把证书掉包吗？**\n\n假设有另一个网站B也拿到了CA机构认证的证书，它想劫持网站A的信息。于是它成为中间人拦截到了A传给浏览器的证书，然后替换成自己的证书，传给浏览器，之后浏览器就会错误地拿到B的证书里的公钥了，这确实会导致上文“中间人攻击”那里提到的漏洞？\n\n其实这并不会发生，因为证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。\n\n##### **为什么制作数字签名时需要hash一次？**。\n\n最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而hash后得到的是固定长度的信息（比如用md5算法hash后可以得到固定的128位的值），这样加解密就快很多。\n\n#### HTTP是基于TCP还是UDP？\n\nHTTP/3.0 之前是基于 TCP 协议的，而 HTTP/3.0 将弃用 TCP，改用 **基于 UDP 的 QUIC 协议** 。\n\n\n\n#### cookie与session\n\n##### Cookie：客户端浏览器用来保存服务端数据的一种机制。\n\n当通过浏览器进行网页访问的时候，服务器可以把某一些状态数据以 key-value 的方式写入到 Cookie 里面存储到客户端浏览器。\n然后客户端下一次再访问服务器的时候，就可以携带这些状态数据发送到服务器端，服务端可以根据 Cookie 里面携带的内容来识别使用者。\n\n##### Session 表示一个会话，它是属于服务器端的容器对象\n\n默认情况下，针对每一个浏览器的请求。Servlet 容器都会分配一个 Session。\nSession 本质上是一个 ConcurrentHashMap，可以存储当前会话产生的一些状态数据。\n我们都知道，Http 协议本身是一个无状态协议，也就是服务器并不知道客户端发送过来的多次请求是属于同一个用户。\n所以 Session 是用来弥补 Http 无状态的不足，简单来说，服务器端可以利用 session来存储客户端在同一个会话里面的多次请求记录。\n基于服务端的 session 存储机制，再结合客户端的 Cookie 机制，就可以实现有状态的Http 协议。\n\n具体的工作原理是：\n客户端第一次访问服务端的时候，服务端会针对这次请求创建一个会话，并生成一个唯一的 sessionId 来标注这个会话。\n然后服务端把这个 sessionid 写入到客户端浏览器的 cookie 里面，用来实现客户端状态的保存。\n在后续的请求里面，每次都会携带 sessionid，服务器端就可以根据这个 sessionid 来识别当前的会话状态。\n\n![image-20231003112158828](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112158828.png)\n\n所以，总的来看，Cookie 是客户端的存储机制，Session 是服务端的存储机制。\n这两者结合使用，来实现会话状态的存储，以上就是我对这个问题的理解！\n\n####  如何实现Session共享？用户A 访问服务器A 在A中存储了你的session  但是A再次访问的时候访问了B服务器  如何保证你的session共享给B \n\n##### 1.[Nginx](https://so.csdn.net/so/search?q=Nginx&spm=1001.2101.3001.7020)的 IP_Hash 策略（可以使⽤）\n\n同⼀个客户端IP的请求都会被路由到同⼀个⽬标服务器，也叫做会话粘滞\n**优点：**\n\n- 配置简单，不⼊侵应⽤，不需要额外修改代码\n  **缺点：**\n- 服务器重启Session丢失\n- 存在单点负载⾼的⻛险\n- 单点故障问题\n\n Session共享，Session集中存储（推荐）\n\n##### 2. 把Session数据存放到Redis中\n\nSessionId 和 session\n\n优点:\n\n能适应各种负载均衡策略\n服务器重启或者宕机不会造成Session丢失\n扩展能⼒强\n适合⼤集群数量使⽤\n缺点：\n对应⽤有⼊侵，引⼊了和Redis的交互代码\n\n\n\n\n\n## 操作系统\n\n\n\n进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。\n\n线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器（**线程切换后能恢复到正确的执行位置**）**、**虚拟机栈（**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的）**和**本地方法栈**（包含局部变量，本地方法），所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。\n\nJava 中，线程作为最小调度单位，进程作为资源分配的最小单位。 在 windows 中进程是不活动的，只是作为线程的容器**。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。**\n\n![image-20231003112203309](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112203309.png)\n\n- 堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存\n- 方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n#### 使用哪个命令去查看一个进程的信息\n\n##### windows\n\n- 任务管理器可以查看进程和线程数，也可以用来杀死进程\n- tasklist 查看进程\n- taskkill 杀死进程\n\n##### linux\n\n- ps -fe 查看所有进程\n- ps -fT -p <PID> 查看某个进程（PID）的所有线程\n- kill 杀死进程\n- top 按大写 H 切换是否显示线程\n- top -H -p <PID> 查看某个进程（PID）的所有线程\n\n##### Java\n\n- jps 命令查看所有 Java 进程\n- jstack <PID> 查看某个 Java 进程（PID）的所有线程状态\n- jconsole 来查看某个 Java 进程中线程的运行情况（图形界面）\n\n\n\n\n\n## JUC\n\n#### 进程与线程\n\n进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。\n\n线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器（**线程切换后能恢复到正确的执行位置**）**、**虚拟机栈（**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的）**和**本地方法栈**（包含局部变量，本地方法），所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。\n\nJava 中，线程作为最小调度单位，进程作为资源分配的最小单位。 在 windows 中进程是不活动的，只是作为线程的容器**。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。**\n\n![image-20231003112209457](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112209457.png)\n\n- 堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存\n- 方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n\n\n#### 单核 CPU 上运行多个线程效率一定会高吗？\n\n单核CPU同时运行多个线程的效率是否会高，取决于线程的类型和任务的性质。两种类型的线程：CPU密集型和IO密集型。\n\n- CPU密集型的线程主要进行计算和逻辑处理，需要占用大量的CPU资源。\n- IO密集型的线程主要进行输入输出操作，如读写文件、网络通信等，需要等待IO设备的响应，而不占用太多的CPU资源。\n\n在单核CPU上，同一时刻只能有一个线程在运行，其他线程需要等待CPU的时间片分配。如果线程是CPU密集型的，那么多个线程同时运行会导致频繁的线程切换，增加了系统的开销，降低了效率。\n\n如果线程是IO密集型的，那么多个线程同时运行可以利用CPU在等待IO时的空闲时间，提高了效率。\n\n因此，对于单核CPU来说，如果任务是CPU密集型的，那么开很多线程会影响效率；如果任务是IO密集型的，那么开很多线程会提高效率。当然，这里的“很多”也要适度，不能超过系统能够承受的上限。\n\n#### 线程创建方法\n\n方法一，直接使用 Thread\n\n```\n/ 创建线程对象\nThread t = new Thread() {\npublic void run() {\n\t\t// 要执行的任务\n\t\t }\n};\n// 启动线程\nt.start();\n```\n\n方法二，使用 Runnable 配合 Thread\nRunnable 可运行的任务（线程要执行的代码）\n\n```\nRunnable runnable = new Runnable() {\npublic void run(){\n\t\t// 要执行的任务\n\t\t}\n};\n// 创建线程对象\nThread t = new Thread( runnable );\n// 启动线程\nt.start();\n```\n\n方法三，FutureTask 配合 Thread\n\nFutureTask 能够接收 Callable 类型的参数，用来处理有返回结果的情况\n\n```\n// 创建任务对象\nFutureTask<Integer> task3 = new FutureTask<>(() -> {\nlog.debug(\"hello\");\nreturn 100;\n});\n\n/ 参数1 是任务对象; 参数2 是线程名字，推荐\nnew Thread(task3, \"t3\").start();\n// 主线程阻塞，同步等待 task 执行完毕的结果\nInteger result = task3.get();\nlog.debug(\"结果是:{}\", result);\n```\n\n#### Java内存区域，内存模型？\n\n**Java内存模型（JMM）**\n\n可以把 JMM 看作是 Java 定义的并发编程相关的一组规范，除了抽象了线程和主内存之间的关系之外，其还规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的。\n\n![image-20231003112214089](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112214089.png)\n\n在当前的 Java 内存模型下，线程可以把变量保存 **本地内存** （比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。\n\n\n\n**Java内存区域**\n\nJava的内存区域和内存模型是不一样的东西，内存区域是指 JVM 运行时将数据分区域存储，强调对内存空间的划分。\n\nJava内存区域主要由栈、堆、方法区组成\n\n**栈**：每个线程有自己独立、不共享的虚拟机栈，由多个栈帧（每个方法运行时需要的内存）组成，其中存放参数、局部变量，返回地址等，每个线程只能有一个活动栈帧，对应当前正在执行的那个方法。\n\n**堆**：多个线程共享同一个堆，通过new关键字构建的对象都需要使用堆内存，里面存放了实例对象、字符串常量池，静态变量等。\n\n**方法区**：保存在着被加载过的每一个类的信息，包括类的方法、构造器，成员方法，属性等，这些信息由[类加载](https://so.csdn.net/so/search?q=类加载&spm=1001.2101.3001.7020)器在加载类时，从类的源文件中抽取出来；**运行时常量池**：当该类被加载时，它的常量池信息就会放入运行时常量池，并把里面的符号地址转换为真实地址。\n\n**程序计数器：**每个线程都有一个独立的程序计数器，记录下一条JVM指令的执行地址\n\n**本地方法栈：**调用本地方法（由C或者C++编写的底层的方法，与操作系统的底层API打交道）时给本地方法提供的内存空间\n\n![image-20231003112225692](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112225692.png)\n\n\n\n#### 线程的上下文切换是什么\n\n因为以下一些原因导致 cpu 不再执行当前的线程，转而执行另一个线程的代码\n\n- 线程的 CPU 时间片用完\n- 垃圾回收\n- 有更高优先级的线程需要运行，CPU被抢占\n- 线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法\n- 主动让出CPU调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。\n\n线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 **上下文切换**。\n\n当 Context Switch 发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，Java 中对应的概念\n就是程序计数器（Program Counter Register），它的作用是记住下一条 jvm 指令的执行地址，是线程私有的\n\n状态包括程序计数器、虚拟机栈中每个栈帧的信息，如局部变量、操作数栈、返回地址等\nContext Switch 频繁发生会影响性能\n\n![image-20231003112229884](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112229884.png)\n\n\n\n#### 什么是线程死锁\n\n多个线程同时被阻塞，处于相互等待的状态，如果没有外界干预，线程会被无限期地阻塞，因此程序不可能正常终止\n\n##### 条件\n\n互斥条件：该资源任意一个时刻只由一个线程占用。\n\n请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。\n\n不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。\n\n循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系\n\n##### 预防\n\n**破坏请求与保持条件**：一次性申请所有的资源。\n\n**破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\n\n**破坏循环等待条件**：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。\n\n\n\n#### 解释多线程的同步\n\n处理多线程问题时，多个线程访问同一个对象，并且某些线程还想修改这个对象。 这时候，我们就需要用到“线程同步”。 **线程同步其实就是一种等待机制**，**多个需要同时访问此对象的线程进入这个对象的**等待池,形成队列，等待前面的线程使用完毕后，下一个线程再使用。\n\n- **同步**：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。\n- **异步**：调用在发出之后，不用等待返回结果，该调用直接返回。\n\n\n\n#### start和 run方法的区别\n\n- 直接调用 run 是在主线程中执行了 run，没有启动新的线程\n\n- 使用 start 是启动新的线程，通过新的线程间接执行 run 中的代码\n\nnew 一个 `Thread`，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\n\n**总结：调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**\n\n\n\n#### java里面线程有几种状态？\n\n#####  操作系统 层面来描述\n\n![image-20231003112235300](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112235300.png)\n\n- 【初始状态】仅是在语言层面创建了线程对象，还未与操作系统线程关联\n- 【可运行状态】（就绪状态）指该线程已经被创建（与操作系统线程关联），可以由 CPU 调度执行\n- 【运行状态】指获取了 CPU 时间片运行中的状态 ：当 CPU 时间片用完，会从【运行状态】转换至【可运行状态】，会导致线程的上下文切换\n- 【阻塞状态】：如果调用了阻塞 API，如 BIO 读写文件，这时该线程实际不会用到 CPU，会导致线程上下文切换，进入\n- 【阻塞状态】：等 BIO 操作完毕，会由操作系统唤醒阻塞的线程，转换至【可运行状态】与【可运行状态】的区别是，对【阻塞状态】的线程来说只要它们一直不唤醒，调度器就一直不会考虑调度它们\n- 【终止状态】表示线程已经执行完毕，生命周期已经结束，不会再转换为其它状态\n\n##### Java API 层面来描述\n\n![image-20231003112238774](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112238774.png)\n\n- NEW: 初始状态，线程被创建出来但没有被调用 `start()` 。\n\n  RUNNABLE: 运行状态，线程被调用了 `start()`等待运行的状态。\n\n  BLOCKED：阻塞状态，需要等待锁释放。\n\n  WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。\n\n  TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。\n\n  TERMINATED：终止状态，表示该线程已经运行完毕.\n\n  ![image-20231003112242092](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112242092.png)\n\n\n\n#### 阻塞和等待有什么区别？\n\n阻塞会持有临界资源并等待，等待会释放临界资源，不过概念还是比较模糊\n\n#### 什么情况下会让线程进入 block 状态\n\n- t 线程用 synchronized(obj) 获取了对象锁时如果竞争失败，从 RUNNABLE --> BLOCKED\n- 持 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有 BLOCKED 的线程重新竞争，如果其中 t 线程竞争成功，从 BLOCKED --> RUNNABLE ，其它失败的线程仍然 BLOCKED\n\n\n\n#### 线程调用sleep方法，sleep(10s)，结束后，调用sleep的线程处于什么状态？\n\n在sleep的时间内，线程不会释放临界资源，在sleep结束之后，线程正常运行，sleep一般是模拟一些业务，之后unlock就释放了临界资源，比如锁\n\n#### 有哪些线程安全的容器？\n\n##### 不可变类：\n\n- String：String的各个substring、replace、reverse 等方法都是重新new一个String对象，不会改变源对象，而且用final修饰，不会有子类覆盖String的方法，不会出现线程安全问题\n- Integer 类似String\n- Random 类似String\n\n##### 遗留的线程安全集合\n\n- StringBuﬀer 对方法加上了synchronized锁，保证线程安全，但是效率比StringBuilder低一些\n- Vector 每个方法都加上了synchronized 关键字，串行化执行，效率低下。而且多线程下组合调用这些方法还是会出现线程不安全。\n- Hashtable： 每个方法都加上了synchronized 关键字，串行化执行，效率低下。而且多线程下组合调用这些方法还是会出现线程不安全。\n\n##### 经过修饰的线程安全的集合\n\n- synchronizedList 、synchronizedMap 、 synchronizedSet等等， 把不安全的list、map、set等作为构造的参数， 其方法使用synchronized(mutex) {map.get();} 使用的还是原本集合中的方法，但是通过synchronized和信号量来实现同步\n\n##### java.util.concurrent 包下的类 \n\nconcurrentHashMap。\n\ncopyOnWriteArrayList: `CopyOnWriteArrayList` 中的读取操作是完全无需加锁的。更加厉害的是，写入操作也不会阻塞读取操作，只有写写才会互斥。这样一来，读操作的性能就可以大幅度提升。\n\n`CopyOnWriteArrayList` 线程安全的核心在于其采用了 **写时复制（Copy-On-Write）** 的策略，从 `CopyOnWriteArrayList` 的名字就能看出了。\n\n当需要修改（ `add`，`set`、`remove` 等操作） `CopyOnWriteArrayList` 的内容时，不会直接修改原数组，而是会先创建底层数组的副本，对副本数组进行修改，修改完之后再将修改后的数组赋值回去，这样就可以保证写操作不会影响读操作了。\n\n\n\nBlockingQueue的实现类:阻塞队列（`BlockingQueue`）被广泛使用在“生产者-消费者”问题中，其原因是 `BlockingQueue` 提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。\n\n\n\n\n\n线程安全的类不一定能保证线程安全，只能保证单个方法执行是线程安全的，但是多个方法的组合还是会出现不安全\n\n```\nMap<String, Integer> map = new concurrentHashMap<>();\nint count = map.get(str);\n//在此处时间片结束，线程不安全\nmap.put(str,count == 0 : 1 ? count + 1);;\n```\n\n\n\n#### 类锁与对象锁的区别：\n\n##### **类锁**\n\n类锁是加载类上的，而类信息是存在 JVM 方法区的，并且整个 JVM 只有一份，方法区又是所有线程共享的，所以类锁是所有线程共享的，所以同一时刻，只能有一个线程使用加了锁的方法或方法体，不管是不是同一个实例。\n\n##### 对象锁\n\n使用对象锁的情况，只有使用同一实例的线程才会受锁的影响，多个实例调用同一方法也不会受影响。\n\n#### 说一下synchronized关键字底层原理\n\nsynchronized的底层是通过monitor对象来实现的。\n\nJava对象在内存中的布局大致可以分为三部分：**对象头**、**实例数据**和**填充对齐**。因为`synchronized`用的锁是存在对象头里的，这里我们需要重点了解对象头。如果对象头是数组类型，则对象头由**Mark Word**、**Class MetadataAddress**和**Array length**组成，如果对象头非数组类型，对象头则由**Mark Word**和**Class MetadataAddress**组成。\n\n\n\n每个 Java 对象都可以关联一个 Monitor 对象，如果使用 synchronized 给对象上锁（重量级）之后，该对象头的Mark Word 中就被设置指向 Monitor 对象的指针\n\n![image-20231003112246654](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112246654.png)\n\nmonitor对象中有owner用来指示拥有锁的对象，entrylist来存放阻塞的线程（竞争失败的线程），waitSet来存放wating的线程（wait()方法），初始时，Monitor中的Owner为null，当第一个竞争锁的线程获得锁，其他的竞争这个锁的线程就会被放入EntryList等待，当获得锁的线程执行完同步代码块中的内容，就会唤醒EntryList中等待的线程，发生非公平竞争这个锁。\n注意：\nsynchronized 必须是进入同一个对象的 monitor 才有上述的效果\n\n\n\n**`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。**\n\n上面的字节码中包含一个 `monitorenter` 指令以及两个 `monitorexit` 指令，这是为了保证锁在同步代码块代码正常执行以及出现异常的这两种情况下都能被正确释放。\n\n当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 **对象监视器 `monitor`**（每个Java对象都可以关联一个monitor对象） 的持有权。\n\n```\n在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由[ObjectMonitoropen in new window](https://github.com/openjdk-mirror/jdk7u-hotspot/blob/50bdefc3afe944ca74c3093e7448d6b889cd20d1/src/share/vm/runtime/objectMonitor.cpp)实现的。每个对象中都内置了一个 `ObjectMonitor`对象。\n\n另外，`wait/notify`等方法也依赖于`monitor`对象，这就是为什么只有在同步的块或者方法中才能调用`wait/notify`等方法，否则会抛出`java.lang.IllegalMonitorStateException`的异常的原因。\n```\n\n在执行`monitorenter`时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。\n\n![image-20231003112249933](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112249933.png)\n\n对象锁的的拥有者线程才可以执行 `monitorexit` 指令来释放锁。在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。\n\n![image-20231003112256314](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112256314.png)\n\n如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n\n##### synchronized 修饰方法的的情况\n\n`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n\n如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。\n\n##### 总结\n\n`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。\n\n`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。\n\n**不过两者的本质都是对对象监视器 monitor 的获取。**\n\n\n\n#### 为什么wait和notify方法要写在synchronized同步代码块中？\n\n这是Java设计者为了避免使用者出现lost wake up问题而搞出来的\n\n![image-20231003112303623](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112303623.png)\n\n问题的根源在于，消费者在检查count到调用wait()之间，count就可能被改掉了。\n\n常见的解决方式是加锁\n\n\n\n\n\n\n\n#### jdk1.7对synchorinzed的优化？ \n\n##### 轻量级锁\n\n轻量级锁的使用场景：如果一个对象虽然有多线程要加锁，但加锁的时间是错开的（也就是没有竞争），那么可以\n使用轻量级锁来优化。\n\n##### 自旋优化\n\n重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步\n块，释放了锁），这时当前线程就可以避免阻塞。\n\n##### 偏向锁\n\n轻量级锁在没有竞争时（就自己这个线程），每次重入仍然需要执行 CAS 操作。\nJava 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现\n这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有\n\n##### 批量重偏向 \n\n如果对象虽然被多个线程访问，但没有竞争，这时偏向了线程 T1 的对象仍有机会重新偏向 T2，重偏向会重置对象\n的 Thread ID\n当撤销偏向锁阈值超过 20 次后，jvm 会这样觉得，我是不是偏向错了呢，于是会在给这些对象加锁时重新偏向至加锁线程\n\n##### 批量撤销\n\n当撤销偏向锁阈值超过 40 次后，jvm 会这样觉得，自己确实偏向错了，根本就不该偏向。于是整个类的所有对象都会变为不可偏向的，新建的对象也是不可偏向的\n\n#### Reentrantlock 与 synchronized 的区别\n\nSynchronized 可以通过两种方式来控制锁的粒度\n\n- 一种是把 synchronized 关键字修饰在方法层面，\n- 另一种是修饰在代码块上，并且我们可以通过 Synchronized 加锁对象的声明周期来控制锁的作用范围，比如锁对象是静态对象或者类对象，那么这个锁就是全局锁。如果锁对象是普通实例对象，那这个锁的范围取决于这个实例的声明周期。\n\nLock 锁的粒度是通过它里面提供的 lock()和 unlock()方法决定的（贴图），包裹在这两个方法之间的代码能够保证线程安全性。而锁的作用域取决于 Lock 实例的生命周期\n\n相对于 synchronized 它具备如下特点\n\n- 可以设置超时时间， Lock 还提供了非阻塞的竞争锁方法 tryLock(int time)方法，在规定时间获取不到锁会返回false\n- **等待可中断** : `ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。\n- **可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock`默认情况是非公平的，可以通过 `ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来指定是否是公平的。\n- **可实现选择性通知（支持多个条件变量）**: `synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。\n\n与 synchronized 一样，都支持可重入\n\n\n\n#### 可中断锁和不可中断锁有什么区别？\n\n- **可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。\n- **不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 `synchronized` 就属于是不可中断锁\n\n\n\n#### volatile关键字的原理？怎么用？是否保证原子性？\n\n由于JVM缓存优化，线程读变量值时，可能会到自己的工作缓存去读而不是到内存，所以当一个线程对变量执行写操作到内存，可能其他线程无法读到最新的变量值。\n\n用法：在多线程读，一线程写的情况下，用来修饰成员变量和静态成员变量，这就指示 JVM，这个变量是共享且不稳定的，他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存。\n\n##### 如何保证可见性\n\n![image-20231003112310433](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112310433.png)\n\n![image-20231003112313979](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112313979.png)\n\n![image-20231003112317775](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112317775.png)\n\nVolatile关键字底层实现主要是通过汇编lock指令，当某个CPU修改了缓存里面的数据，该数据会马上通过总线同步回主存，（lock指令开启其他CPU的总线嗅探机制）其他CPU通过一个**总线嗅探机制**来感知数据的变化从而将自己缓存里面的数据失效，需要使用这个数据，必须重新去内存中获取最新的数据，来保证数据的可见性。\n\n- 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中\n\n```\npublic void actor2(I_Result r) {\nnum = 2;\nready = true; // ready 是 volatile 赋值带写屏障\n// 写屏障\n}\n```\n\n- 而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据\n\n```\npublic void actor1(I_Result r) {\n// 读屏障\n// ready 是 volatile 读取值带读屏障\n\tif(ready) {\n\tr.r1 = num + num;\n\t} else {\n\tr.r1 = 1;\n\t}\n}\n```\n\n##### 保证有序性\n\n当对volatile修饰变量赋值，会加上写屏障，写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后\n\n```\npublic void actor2(I_Result r) {\nnum = 2;\nready = true; // ready 是 volatile 赋值带写屏障\n// 写屏障\n}\n```\n\n当对volatile修饰变量取值，会加上读屏障，读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前\n\n```\npublic void actor1(I_Result r) {\n// 读屏障\n// ready 是 volatile 读取值带读屏障\nif(ready) {\nr.r1 = num + num;\n} else {\nr.r1 = 1;\n}\n}\n```\n\n##### 不能解决指令交错（无法保证原子性）：\n\n写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证读跑到它前面去\n而有序性的保证也只是保证了本线程内相关代码不被重排序\n\n#### synchronized关键字保证可见性和有序性\n\n我们都知道sychronized底层是通过monitorenter的指令来进行加锁的、通过monitorexit指令来释放锁的。\n\n但是很多人都不知道的一点是，monitorenter指令其实还具有Load屏障的作用。\n\n也就是通过monitorenter指令之后，synchronized内部的共享变量，每次读取数据的时候被强制从主内存读取最新的数据。\n\n同样的道理monitorexit指令也具有Store屏障的作用，也就是让synchronized代码块内的共享变量，如果数据有变更的，强制刷新回主内存。\n\n这样通过这种方式，数据修改之后立即刷新回主内存，其他线程进入synchronized代码块后，使用共享变量的时候强制读取主内存的数据，上一个线程对共享变量的变更操作，它就能立即看到了。\n\n同时synchronized加的内存屏障也能保证内部代码的有序性\n\n![image-20231003112322766](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112322766.png)\n\n#### 为什么单线程不需要这个volatile关键字多线程需要 \n\n因为在单线程的环境下，只有一个线程会使用修改的变量，变量不存在可见性问题。同时，单线程下，JVM的指令重排序也不会改变执行结果。\n\n\n\n#### 为什么会出现指令重排序：\n\n指令还可以再划分成一个个更小的阶段，在不改变程序结果的前提下，这些指令的各个阶段可以通过重排序和组合来实现指令级并行，从而提高CPU的吞吐率。\n\n\n\n\n\n#### 多线程通信方式\n\n\n\n在Java中，多线程通信是通过一些机制和方法来实现的，以确保不同线程之间能够协同工作。以下是一些常见的多线程通信方式：\n\n1. **共享变量：** 多个线程可以共享一个变量，通过读写该变量来进行通信。为了确保线程安全，通常需要使用`volatile`关键字或者`synchronized`关键字来控制访问。例如：\n\n```\njavaCopy codeclass SharedResource {\n    private volatile int sharedValue;\n\n    public void setValue(int value) {\n        sharedValue = value;\n    }\n\n    public int getValue() {\n        return sharedValue;\n    }\n}\n```\n\n1. **wait()和notify()：** 这是基于对象监视器（Object Monitor）的机制，用于线程之间的等待和通知。`wait()`方法让一个线程等待，而`notify()`方法通知等待的线程继续执行。通常与`synchronized`关键字一起使用。\n\n```\njavaCopy codeclass SharedResource {\n    private int sharedValue;\n\n    public synchronized void setValue(int value) {\n        sharedValue = value;\n        notify(); // 通知等待的线程\n    }\n\n    public synchronized int getValue() throws InterruptedException {\n        if (sharedValue == 0) {\n            wait(); // 等待通知\n        }\n        return sharedValue;\n    }\n}\n```\n\n1. **BlockingQueue：** 使用`java.util.concurrent.BlockingQueue`可以方便地实现线程之间的通信。它提供了阻塞操作，当队列为空或已满时，线程会自动阻塞或等待。例如，`LinkedBlockingQueue`可以用于生产者-消费者问题。\n\n```\njavaCopy codeimport java.util.concurrent.*;\n\nBlockingQueue<Integer> queue = new LinkedBlockingQueue<>();\n\n// 生产者线程\nvoid producer() throws InterruptedException {\n    queue.put(1);\n}\n\n// 消费者线程\nvoid consumer() throws InterruptedException {\n    int value = queue.take();\n}\n```\n\n1. **CountDownLatch和CyclicBarrier：** 这两个类用于协调多个线程的执行。`CountDownLatch`用于等待一个或多个线程的完成，而`CyclicBarrier`用于等待多个线程到达某个同步点。\n\n```\njavaCopy codeCountDownLatch latch = new CountDownLatch(3);\n\n// 多个线程执行任务\nfor (int i = 0; i < 3; i++) {\n    new Thread(() -> {\n        // 执行任务\n        latch.countDown(); // 任务完成，计数减一\n    }).start();\n}\n\n// 主线程等待所有任务完成\nlatch.await();\n```\n\n1. **Semaphore：** `java.util.concurrent.Semaphore`用于控制同时访问的线程数量。它允许多个线程同时访问一个共享资源。\n\n```\njavaCopy codeSemaphore semaphore = new Semaphore(3); // 最多允许3个线程同时访问\n\n// 线程尝试获取许可\ntry {\n    semaphore.acquire(); // 获取许可\n    // 访问共享资源\n} catch (InterruptedException e) {\n    e.printStackTrace();\n} finally {\n    semaphore.release(); // 释放许可\n}\n```\n\n这些是Java中常见的多线程通信方式。选择合适的通信方式取决于问题的性质和需求。需要注意，不正确的多线程通信可能导致竞态条件和死锁等问题，因此在设计多线程应用程序时应格外小心。\n\n#### 乐观锁和悲观锁的区别？\n\n##### **什么悲观锁？**\n\n顾名思义，悲观锁是基于一种悲观的态度类来防止一切数据冲突，它是以一种预防的姿态在修改数据之前把数据锁住，然后再对数据进行读写，在它释放锁之前任何人都不能对其数据进行操作，直到前面一个人把锁释放后下一个人数据加锁才可对数据进行加锁，然后才可以对数据进行操作，一般数据库本身锁的机制都是基于悲观锁的机制实现的;\n\n特点：可以完全保证数据的独占性和正确性，因为每次请求都会先对数据进行加锁， 然后进行数据操作，最后再解锁，而加锁释放锁的过程会造成消耗，所以性能不高;\t\t高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。并且，悲观锁还可能会存在死锁问题，影响代码的正常运行。\n\n\n\n##### **什么是乐观锁？**\n\n乐观锁是对于数据冲突保持一种乐观态度，操作数据时不会对操作的数据进行加锁（这使得多个任务可以并行的对数据进行操作），只有到数据提交的时候才通过一种机制来验证数据是否存在冲突(一般实现方式是通过加版本号然后进行版本号的对比方式实现);\n\n特点：乐观锁是一种并发类型的锁，其本身不对数据进行加锁通而是通过业务实现锁的功能，不对数据进行加锁就意味着允许多个请求同时访问数据，同时也省掉了对数据加锁和解锁的过程，这种方式因为节省了悲观锁加锁的操作，所以可以一定程度的的提高操作的性能，不过在并发非常高的情况下，会导致大量的请求冲突，冲突导致大部分操作无功而返而浪费资源，所以在高并发的场景下，乐观锁的性能却反而不如悲观锁。\n\n##### 理论上来说：\n\n- 悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如`LongAdder`），也是可以考虑使用乐观锁的，要视实际情况而定。\n- 乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考`java.util.concurrent.atomic`包下面的原子变量类）。\n\n\n\n#### 讲一下CAS\n\nCAS是一种无锁同步机制，其中的关键是 compareAndSet，也有 Compare And Swap 的说法，它必须是原子操作。\n\n**CAS 必须借助 volatile** 才能读取到共享变量的最新值来实现【比较并交换】的效果\n\nCAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。\n\nCAS指令执行时，**当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。通过发送一个lock指令锁住总线，确保整个比较并替换的操作是一个原子操作。**\n\n##### CAS 的特点\n\n- 结合 CAS 和 volatile 可以实现无锁并发，适用于线程数少、竞争较少，多核 CPU 的场景下。\n- CAS 是基于乐观锁的思想：最乐观的估计，预计很少出现并发问题，当出现后，再重试。\n- synchronized 是基于悲观锁的思想：最悲观的估计，得防着其它线程来修改共享变量，当一个线程上了锁，其他线程只能阻塞等待解锁。使得线程只能串行访问同步代码块，效率较低。\n- CAS 体现的是无锁并发、无阻塞并发，请仔细体会这两句话的意思\n- 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一\n- 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响\n\n##### 缺点\n\n**循环时间长开销很大：**我们可以看到getAndAddInt方法执行时，如果CAS失败，会一直进行尝试。如果CAS长时间一直不成功，可能会给CPU带来很大的开销。\n\n**只能保证一个共享变量的原子操作：**当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性。\n\n**ABA*问题**：**通过版本号法解决。**Java并发包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。因此，在使用CAS前要考虑清楚“ABA”问题是否会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。\n\n##### 用处：\n\nAutomic原子类，多线程的互斥同步等\n\n\n\n#### LongAdder\n\n##### **LongAdder的成员变量**\n\n```text\n// CPU的数量\nstatic final int NCPU = Runtime.getRuntime().availableProcessors();\n// Cell对象的数组，长度一般是2的指数\ntransient volatile Cell[] cells;\n// 基础value值，当并发较低时，只累加该值\ntransient volatile long base;\n// 创建或者扩容Cells数组时使用的自旋锁变量\ntransient volatile int cellsBusy;\n```\n\n当并发量较少时，cell数组尚未初始化，所以只调用`casBase`函数，对base变量进行CAS累加。\n\n并发量大时，放弃使用base变量，而是从cells数组中随机选择一个cell，CAS累加，这样就可以减少并发冲突，获取值就用base加上cells中所有元素累加获得值，遍历数组不是个原子操作，所以LongAdder取到的值不是最新值，再获取精确计数的场景，可能不适合。\n\n\n\n#### 线程池的好处\n\n- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。\n- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。\n- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n\n\n#### 线程池的拒绝策略有哪些？\n\n若线程池中的核心线程数被用完且阻塞队列已排满，则此时线程池的资源已耗尽，线程池将没有足够的线程资源执行新的任务。为了保证操作系统的安全，线程池将通过拒绝策略处理新添加的线程任务。\n\n##### **1. AbortPolicy**（默认策略）\n\n第一种拒绝策略是 `AbortPolicy`，这种拒绝策略在拒绝任务时，会直接抛出一个类型为 RejectedExecutionException的RuntimeException，让你感知到任务被拒绝了，于是你便可以根据业务逻辑选择重试或者放弃提交等策略。\n\n##### **2.DiscardPolicy**\n\n第2种拒绝策略是 `DiscardPolicy`，这种拒绝策略正如它的名字所描述的一样，当新任务被提交后直接被丢弃掉，也不会给你任何的通知，相对而言存在一定的风险，因为我们提交的时候根本不知道这个任务会被丢弃，可能造成数据丢失。\n\n##### **3.DiscardOldestPolicy**\n\n第3种拒绝策略是 `DiscardOldestPolicy`，如果线程池没被关闭且没有能力执行，则会丢弃任务队列中的头结点，通常是存活时间最长的任务，这种策略与第二种不同之处在于它丢弃的不是最新提交的，而是队列中存活时间最长的，这样就可以腾出空间给新提交的任务，但同理它也存在一定的数据丢失风险。\n\n##### **4.CallerRunsPolicy**\n\n第4种拒绝策略是 CallerRunsPolicy，相对而言它就比较完善了，当有新任务提交后，如果线程池没被关闭且没有能力执行，则把这个任务交于提交任务的线程执行，也就是谁提交任务，谁就负责执行任务。这样做主要有两点好处。\n\n1. 第一点新提交的任务不会被丢弃，这样也就不会造成业务损失。\n2. 第二点好处是，由于谁提交任务谁就要负责执行任务，这样提交任务的线程就得负责执行任务，而执行任务又是比较耗时的，在这段期间，提交任务的线程被占用，也就不会再提交新的任务，减缓了任务提交的速度，相当于是一个负反馈。在此期间，线程池中的线程也可以充分利用这段时间来执行掉一部分任务，腾出一定的空间，相当于是给了线程池一定的缓冲期。\n\n##### **总结**\n\n本文中我们学习线程池中的4 种默认的拒绝策略。线程池会在以下两种情况下会拒绝新提交的任务。\n\n- 第一种情况是当我们调用 shutdown 等方法关闭线程池后，即便此时可能线程池内部依然有没执行完的任务正在执行，但是由于线程池已经关闭，此时如果再向线程池内提交任务，就会遭到拒绝。\n- 第二种情况是线程池没有能力继续处理新提交的任务，也就是工作已经非常饱和的时候。\n\n线程池状态\n\nThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量\n\n![image-20231003112330381](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112330381.png)\n\n```Java\n// c 为旧值， ctlOf 返回结果为新值\nctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))));\n// rs 为高 3 位代表线程池状态， wc 为低 29 位代表线程个数，ctl 是合并它们\nprivate static int ctlOf(int rs, int wc) { return rs | wc; }\n```\n\n\n\n#### 线程池七大参数，向线程池提交任务，为什么核心线程池已满后要加入到等待队列\n\n- ##### corePoolSize 核心线程数目 (最多保留的线程数)\n\n线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会被销毁，除非设置了allowCoreThreadTimeOut。这里的最小线程数量即是corePoolSize。任务提交到线程池后，首先会检查当前线程数是否达到了corePoolSize，如果没有达到的话，则会创建一个新线程来处理这个任务。\n\n- ##### maximumPoolSize 最大线程数目\n\n当前线程数达到corePoolSize后，如果继续有任务被提交到线程池，会将任务缓存到工作队列（后面会介绍）中。如果队列也已满，则会去创建一个新线程来出来这个处理。线程池不会无限制的去创建新线程，它会有一个最大线程数量的限制，这个数量即maximunPoolSize指定\n\n- ##### keepAliveTime 生存时间 - 针对救急线程，当没有任务一段时间会被销毁\n\n线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，多余的空闲线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁，线程池回收线程时，会对核心线程和非核心线程一视同仁，直到线程池中线程的数量等于 `corePoolSize` ，回收过程才会停止。\n\n- ##### unit 时间单位 - 针对多余空闲线程， 救急线程存活时间单位\n\n- ##### workQueue 阻塞队列\n\n当线程数达到 corePoolSize 并没有线程空闲，这时再加入任务，新加的任务会被加入workQueue 队列排\n队，直到有空闲的线程\n\n- ##### threadFactory 线程工厂 - 可以为线程创建时起个好名字\n\n创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon（守护线程）线程等等\n\n- ##### handler 拒绝策略\n\n当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这时如果有新任务提交进来，就会采用拒绝策略\n\n\n\n#### \n\n\n\n####  创建多少线程池合适（线程池的参数怎么设计）\n\n- 过小会导致程序不能充分地利用系统资源、容易导致饥饿\n- 过大会导致更多的线程上下文切换，占用更多内存\n\n#####  CPU 密集型运算\n\n通常采用 cpu 核数 + 1 能够实现最优的 CPU 利用率，+1 是保证当线程由于页缺失故障（操作系统）或其它原因导致暂停时，额外的这个线程就能顶上去，保证 CPU 时钟周期不被浪费\n\n##### I/O 密集型运算\n\nCPU 不总是处于繁忙状态，例如，当你执行业务计算时，这时候会使用 CPU 资源，但当你执行 I/O 操作时、远程RPC 调用时，包括进行数据库操作时，这时候 CPU 就闲下来了，你可以利用多线程提高它的利用率。\n经验公式如下\n\n线程数 = 核数 * 期望 CPU 利用率 * 总时间(CPU计算时间+等待时间) / CPU 计算时间\n\n例如 4 核 CPU 计算时间是 50% ，其它等待时间是 50%，期望 cpu 被 100% 利用，套用公式\n\n4 * 100% * 100% / 50% = 8\n\n例如 4 核 CPU 计算时间是 10% ，其它等待时间是 90%，期望 cpu 被 100% 利用，套用公式\n\n4 * 100% * 100% / 10% = 40\n\n**公示也只是参考，具体还是要根据项目实际线上运行情况来动态调整**，包括核心线程数、最大线程数、自定义任务队列等等\n\n\n\n\n\n#### 假如有一个高并发低延迟的业务和一个低并发高延迟的业务，应该核心线程的数量应该怎么设置？\n\n- 高并发低延迟业务，低延迟说明大概率是CPU密集型，高并发的情况下为了防止大量的上下文切换，核心线程数不宜设置太高，应该设置大概CPU核数 + 1个线程，\n- 低并发高延迟业务，高延迟说明所需数据或外部资源需要较长时间等待，大概率是IO密集型，核心线程数应该设置为    CPU 核数 * 总时间(CPU计算时间+等待时间) / CPU 计算时间\n\n#### Future 类有什么用？\n\n`Future` 类是异步思想的典型运用，主要用在一些需要执行耗时任务的场景，避免程序一直原地等待耗时任务执行完成，执行效率太低。具体来说是这样的：当我们执行某一耗时的任务时，可以将这个耗时任务交给一个子线程去异步执行，同时我们可以干点其他事情，不用傻傻等待耗时任务执行完成。等我们的事情干完后，我们再通过 `Future` 类获取到耗时任务的执行结果。这样一来，程序的执行效率就明显提高了。\n\n这其实就是多线程中经典的 **Future 模式**，你可以将其看作是一种设计模式，核心思想是异步调用，主要用在多线程领域，并非 Java 语言独有。\n\n在 Java 中，`Future` 类只是一个泛型接口，位于 `java.util.concurrent` 包下，其中定义了 5 个方法，主要包括下面这 4 个功能：\n\n- 取消任务；\n- 判断任务是否被取消;\n- 判断任务是否已经执行完成;\n- 获取任务执行结果。\n\n\n\n#### 讲一讲AQS\n\n##### 介绍\n\n`AbstractQueuedSynchronizer(AQS)`提供了一套可用于实现锁同步机制的框架，不夸张地说，`AQS`是`JUC`同步框架的基石。`AQS`通过一个`FIFO`队列维护线程同步状态，实现类只需要继承该类，并重写指定方法即可实现一套线程同步机制。\n\n`AQS`根据资源互斥级别提供了**独占和共享**两种资源访问模式；同时其定义`Condition`结构提供了`wait/signal`等待唤醒机制。\n\n##### 原理\n\n`AQS`的原理并不复杂，`AQS`维护了一个`volatile int state`变量和一个`CLH(三个人名缩写)先进先出的双向队列`，队列中的节点持有线程引用，每个节点均可通过`getState()`、`setState()`和`compareAndSetState()`对`state`进行修改和访问。具有条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet。\n\n在`JUC`中，诸如`ReentrantLock`、`CountDownLatch`等都基于`AQS`实现。\n\n![image-20231003112335241](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112335241.png)\n\n\n\n![img](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/e22dfb7003ee44afb6f80ddfbce68a93tplv-k3u1fbpfcp-zoom-in-crop-mark1512000-1696303417939-13.webp)\n\n子类主要实现这样一些方法（默认抛出 UnsupportedOperationException）\n\n- tryAcquire\n- tryRelease\n- tryAcquireShared\n- tryReleaseShared\n- isHeldExclusively\n\n#### 公平锁与非公平锁？底层实现是什么\n\n底层都是AQS，默认一般使用**非公平锁**，它的效率和吞吐量都比公平锁高的多。由于公平锁需要关心队列的情况，得按照队列里的先后顺序来获取锁(会造成大量的线程上下文切换)，而非公平锁则没有这个限制。所以也就能解释非公平锁的效率会被公平锁更高。\n\n**公平锁**：\n\n线程在tryAcquire（arg）尝试获得锁之前会利用 hasQueuedPredecessors() 方法来判断 AQS 的队列中中是否有其他线程，如果有则不会尝试获取锁(**这是公平锁特有的情况**)。\n\n如果队列中没有线程就利用 CAS 来将 AQS 中的 state 修改为1，也就是获取锁，获取成功则将当前线程置为获得锁的独占线程(setExclusiveOwnerThread(current))。\n\n如果 state 大于 0 时，说明锁已经被获取了，则需要判断获取锁的线程是否为当前线程(ReentrantLock 支持重入)，是则需要将 state + 1，并将值更新。\n\n如果tryAcquire(arg) 获取锁失败，则需要用 addWaiter(Node.EXCLUSIVE) 将当前线程写入队列中。\n\n写入之前需要将当前线程包装为一个 Node 对象(addWaiter(Node.EXCLUSIVE))，通过自旋加上 CAS 保证一定能写入队列。\n\n\n\n**非公平锁**：尝试获取锁时tryAcquire(arg)，非公平锁是不需要判断队列中是否还有其他线程，也是直接尝试获取锁：\n\n\n\n**`Node`主要包含5个核心字段：**\n\n- waitStatus\n\n  ：当前节点状态，该字段共有5种取值：\n\n  - `CANCELLED = 1`。节点引用线程由于等待超时或被打断时的状态。\n  - `SIGNAL = -1`。后继节点线程需要被唤醒时的当前节点状态。当队列中加入后继节点被挂起`(block)`时，其前驱节点会被设置为`SIGNAL`状态，表示该节点需要被唤醒。\n  - `CONDITION = -2`。当节点线程进入`condition`队列时的状态。(见`ConditionObject`)\n  - `PROPAGATE = -3`。仅在释放共享锁`releaseShared`时对头节点使用。(见共享锁分析)\n  - `0`。节点初始化时的状态。\n\n- `prev`：前驱节点。\n\n- `next`：后继节点。\n\n- `thread`：引用线程，头节点不包含线程。\n\n- `nextWaiter`：`condition`条件队列。(见`ConditionObject`)\n\n\n\n\n\n#### ThreadLocal是什么？怎么用？内存泄漏？在项目中的运用？\n\n![image-20231003112342131](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112342131.png)\n\nthreadLocal 是一个用来解决线程安全性问题的工具。它相当于让每个线程都开辟一块内存空间，用来存储共享变量的副本。\n然后每个线程只需要访问和操作自己的共享变量副本即可，从而避免多线程竞争同一个共享资源。\n它的工作原理很简单（如图）\n\n![image-20231003112345346](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112345346.png)\n\n每个线程里面有一个成员变量 ThreadLocalMap,\n当线程访问用 ThreadLocal 修饰的共享数据的时候\n这个线程就会在自己成员变量 ThreadLocalMap 里面保存一份数据副本。\nkey 指向 ThreadLocal 这个引用，并且是弱引用关系，而 value 保存的是共享数据的副本。\n因为每个线程都持有一个副本，所以就解决了线程安全性问题。\n\nThreadLocal的实现原理，每一个Thread维护一个ThreadLocalMap，key为使用**弱引用**的ThreadLocal实例，value为线程变量的副本。这些对象之间的引用关系如下,\n\n![image-20231003112348542](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112348542.png)\n\n> 实心箭头表示强引用，空心箭头表示弱引用\n\n##### ThreadLocal 内存泄漏的原因\n\n`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。\n\n这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后最好手动调用`remove()`方法\n\n##### 总结\n\n由于Thread中包含变量ThreadLocalMap，因此ThreadLocalMap与Thread的生命周期是一样长，如果都没有手动删除对应key，都会导致内存泄漏。\n\n但是使用**弱引用**可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set(),get(),remove()的时候会被清除。\n\n因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。\n\n##### ThreadLocal正确的使用方法\n\n- 每次使用完ThreadLocal都调用它的remove()方法清除数据\n- （将ThreadLocal变量定义成private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉 。）\n\n\n\n\n\n## JVM\n\n#### jvm堆的分区\n\n\n\n#### 垃圾收集算法\n\n\n\n#### jvm各种区域介绍\n\n**Java内存区域**\n\nJava的内存区域和内存模型是不一样的东西，内存区域是指 JVM 运行时将数据分区域存储，强调对内存空间的划分。\n\nJava内存区域主要由栈、堆、方法区组成\n\n**栈**：每个线程有自己独立、不共享的虚拟机栈，由多个栈帧（每个方法运行时需要的内存）组成，其中存放参数、局部变量，返回地址等，每个线程只能有一个活动栈帧，对应当前正在执行的那个方法。\n\n**堆**：多个线程共享同一个堆，通过new关键字构建的对象都需要使用堆内存，里面存放了实例对象、字符串常量池，静态变量等。\n\n**方法区**：保存在着被加载过的每一个类的信息，包括类的方法、构造器，成员方法，属性等，这些信息由[类加载](https://so.csdn.net/so/search?q=类加载&spm=1001.2101.3001.7020)器在加载类时，从类的源文件中抽取出来；**运行时常量池**：当该类被加载时，它的常量池信息就会放入运行时常量池，并把里面的符号地址转换为真实地址。\n\n**程序计数器：**每个线程都有一个独立的程序计数器，记录下一条JVM指令的执行地址\n\n**本地方法栈：**调用本地方法（由C或者C++编写的底层的方法，与操作系统的底层API打交道）时给本地方法提供的内存空间\n\n![image-20231003112352559](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112352559.png)\n\n**直接内存：**操作系统的内存，分配回收成本较高，读写性能高，不受JVM内存回收管理\n\n\n\n#### 假如让你设计一个malloc()，和free()你会怎么做？\n\n\n\n## Linux常用命令\n\n\n\n## 项目：\n\n#### 你觉得秒杀模块的关键模块和关键设计是什么：\n\n最关键的模块：防止超卖和一人一单的校验\n\n关键设计：CAS 和 分布式锁\n\n#### 介绍一下你的项目？\n\n我做的这个项目是一个仿大众点评的探店评价项目，用到了Spring Boot框架，MybatisPlus操作据数据库，通过Redis缓存热点数据，主要的实现了发布探店笔记，优惠券秒杀，好友关注，点赞评论，查看附近娱乐场所（Redis的GEO功能，先将不同类型的商户id，和经纬度存入Redis，输入当前x,y 经纬度查询指定半径内的商铺ids，再去数据库查询商户的详细信息）对店铺的增删改查（先去Redis中找，如果逻辑过期就开启线程来缓存重建，返回过期数据），等功能\n\n#### 在这个项目中你实现了哪些功能\n\n优惠券秒杀，好友关注，点赞评论，探店笔记的增删改查、查看附近娱乐场所\n\n查看附近娱乐场所：使用Redis中GEO数据类型实现。将所有的商铺信息按照商铺类型在Redis中建立对应的数据然后进行查询即可。\n\n#### 为什么要用redis替代session实现登录注册功能，有什么好处？\n\n多台Tomcat并不共享session存储空间，当请求切换到不同tomcat服务时导致数据丢失的问题，然而使用Redis则保证多个服务器访问的是同一个Redis就实现了数据的共享。此外Redis集群内部的数据一致性机制也很棒\n\n#### 如何解决集群的session共享问题？\n\n在分布式系统下每一个服务器的Session数据是独立的，用户在不同服务器之间切换的时候可能因为session不共享问题而需要反复登录。然而使用Redis则保证多个服务器访问的是同一个Redis就实现了数据的共享。此外Redis集群内部的数据一致性机制也很棒\n\n#### 说一说短信验证码功能如何实现？（string+expire）\n\n当用户输入了手机号，并点击发送验证码，就会生成一个 验证码前缀 拼接 手机号的一个key， 6位随机验证码作为value，保存到Redis缓存中，并设置过期时间为1分钟。\n\n\n\n#### 如何解决了缓存穿透、缓存击穿和缓存雪崩问题？\n\n##### 缓存穿透\n\n缓存穿透是指查询一个缓存和数据库里都没有的数据，每次查询都透过缓存直接查询数据库，最后返回空。当用户使用这条不存在的数据疯狂发起查询请求的时候就会给数据库造成了很大的压力，数据库可能挂掉\n\n##### 解决方案：\n\n1. 缓存空字符串（额外内存消耗，可能造成短期的不一致）对于数据库中没有的数据，向缓存中缓存空值，别再访问数据库了，减少压力\n\n2. 布隆过滤（内存占用少，没有多余key，实现复杂，存在误判可能）\n\n3. 做好数据的基础格式校验\n\n4. 加强用户权限校验（降低恶意攻击的可能）\n\n   \n\n##### 布隆过滤器（一种数据结构）\n\n布隆过滤器是一种数据结构用于快速检查一个元素是否属于某个集合中。它可以快速判断一个元素是否在一个大型集合中，且判断速度很快且不占用太多内存空间。\n\n布隆过滤器原理：\n布隆过滤器的主要原理是使用一组哈希函数，将元素映射成一组bit数组中的索引位置。\n\n- 当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个位数组中的 K 个点，把它们置为 1。\n- 检索的时候，使用同样的方式去映射，只要看到每个映射的位置的值是不是 1，就可以大概知道该元素是否存在集合中了。\n- 如果这些点有任何一个 0，则被检查的元素一定不在；如果都是 1，则被检查的元素很可能存在。\n\n例子：\n\n比如我们一共有3个key，我们对这3个key分别进行3次hash运算，key1经过三次hash运算后的结果分别为2/6/10，那么就把布隆过滤器中下标为2/6/10的元素值更新为1，然后再分别对key2和key3做同样操作，结果如下图：\n\n![image-20231003112356582](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112356582.png)\n\n这样，当客户端查询时，也对查询的key做3次hash运算得到3个位置，然后看布隆过滤器中对应位置元素的值是否为1，如果所有对应位置元素的值都为1，就证明key在库中存在，则继续向下查询；如果3个位置中有任意一个位置的值不为1，那么就证明key在库中不存在，直接返回客户端空即可。如下图：\n\n![image-20231003112359294](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112359294.png)\n\n当客户端查询key4时，key4的3次hash运算中，有一个位置8的值为0，就说明key4在库中不存在，直接返回客户端空即可。\n\n所以，布隆过滤器就相当于一个位于客户端与缓存层中间的拦截器一样，负责判断key是否在集合中存在。如下图：\n\n\n\n\n\n布隆过滤器优缺点：\n布隆过滤器的优点包括：\n\n1.时间和空间效率高：布隆过滤器的时间复杂度和空间复杂度都是O(k)，其中k为哈希函数的数量。因此，它可以在较小的空间内快速判断某个元素是否在集合中。![image-20231003112407380](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112407380.png)\n\n2.误判率低：布隆过滤器虽然可能出现误判，但是误判率可以通过调整哈希函数数量和位数组大小来控制，可以根据实际需求进行调整。\n\n3.支持高并发：布隆过滤器支持并发查询和添加数据，可以在多线程环境下使用。\n\n4.易于实现：布隆过滤器的实现比较简单，只需要实现几个哈希函数和一个位数组即可。\n\n布隆过滤器的缺点包括：\n\n1.无法删除已添加的数据：由于布隆过滤器的哈希函数不具有逆向性，所以无法删除已添加的数据。\n\n2.误判率无法避免：由于布隆过滤器的设计原理，误判率无法避免。当哈希函数的数量不足或位数组的大小不够时，误判率可能会很高。\n\n3.无法精确判断元素是否存在：由于布隆过滤器的设计原理，无法精确判断某个元素是否在集合中，只能判断它可能存在或一定不存在。\n\n减少布隆过滤器的误判：\n布隆过滤器的误判率是根据哈希函数的数量和位数组大小来确定的。如果哈希函数的数量太少或者位数组太小，那么误判率会增加。反之，如果哈希函数的数量太多或者位数组太大，那么可能会导致空间浪费和查询效率降低。因此，在实际使用中，需要根据具体的应用场景来确定哈希函数数量和位数组大小，以达到误判率和空间利用率的平衡。\n\n1.使用多个布隆过滤器：将同一个元素添加到多个布隆过滤器中，查询时需要在所有布隆过滤器中查询。这种方法可以显著降低误判率，但是会增加存储空间和查询时间。\n\n2.使用加密哈希函数：加密哈希函数可以使哈希值更难以预测，从而减少哈希冲突的概率。常见的加密哈希函数包括MD5、SHA-1等。\n\n3.使用高质量的哈希函数：使用高质量的哈希函数可以减少哈希冲突的概率。常见的高质量哈希函数包括MurmurHash、CityHash等。\n\n4.对于数据量较小的情况，可以使用简单的线性查找代替布隆过滤器，这样可以避免误判率过高的问题。\n\n需要注意的是，误判率是布隆过滤器的本质限制，无法完全避免。因此，在使用布隆过滤器时，需要根据实际需求来平衡误判率和空间利用率，同时采用多个布隆过滤器、使用高质量的哈希函数等方法来尽量减少误判率。\n\n\n\n##### 缓存击穿：\n\n缓存击穿是指当缓存中某个热点数据过期了，在该热点数据重新载入缓存之前，有大量的查询请求穿过缓存，直接查询数据库。这种情况会导致数据库压力瞬间骤增，造成大量请求阻塞，甚至直接挂掉。\n\n缓存击穿解决方案：\n\n   1. 使用互斥锁：\n      线程在重建缓存数据时，进行加锁，其他线程等待重试，直到释放锁之后，其他线程就可以缓存命中了。\n\n      保证一致性，实现简单，其他线程需要等待，可能有死锁风险   \t\n\n   2. 逻辑过期：\n      对数据加一个过期时间字段，但并不实际设置过期时间，始终在redis当中。校验发现逻辑时间过期时，获得互斥锁，开新线程去重建缓存数据，本线程返回那个过期的数据，对于其他线程，发现缓存中数据逻辑时间过期时，尝试获取互斥锁失败，就直接返回过期数据。\n      线程无需等待，性能较好，但是有线程直接返回过期数据，不保证数据一致性\n\n##### 缓存雪崩：\n\n缓存雪崩是指当缓存中有大量的key在同一时刻过期，或者Redis直接宕机了，导致大量的查询请求全部到达数据库，造成数据库查询压力骤增，甚至直接挂掉。\n解决方案：\n\n1. 过期时间可以设置随机数，如30+（0~5）分钟随机，不要同时过期，每个key的过期时间分散，让他们的过期时间尽量均匀分散开\n\n2. 给缓存业务添加降级限流策略\n\n3. 给业务添加多级缓存\n\n4. 使用redis集群（主从、哨兵、redis集群）提高可用性（redis宕机）\n\n5. 数据预热：数据预热的含义就是在正式部署之前，先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。\n\n   \n\n#### Redis消息队列\n\nredis消息队列和阻塞队列区别\n1.消息队列是在JVM内存以外的独立服务，不受JVM内存限制\n2.消息队列里的消息会做持久化，不管服务宕机还是重启，数据不会丢失\n3.消息投递给消费者以后，要求消费者做消息的确认，没有确认，消息就会在队列中依然存在，确保消息至少被消费一次\n\n#### 该项目如何使用redis实现唯一的全局id？\n\n用户在对优惠券抢购时一个订单就对应一个订单ID在高并发情况下需要保证ID的以下特点\n\n唯一性（保证全局唯一）\n高可用、高性能 （可以以极快的速度生成唯一ID）\n递增型（递增的ID有利于在数据库中建立索引）\n\n第一位符号位永远为0\n31位 timestamp时间戳（当前时间戳–自定义的起始时间戳）以秒为单位可以使用69年。\n低32位为当天订单数count，并将count 自增后存入redis。\n\n\n\n#### 超卖问题如何解决\n\n超卖问题的产生：高并发环境下获取库存和对库存的更新不是一个原子操作\n\n解决方案\n\n使用悲观锁在下单的业务上使用sync关键字。但是这样会导致秒杀业务变成串行执行严重降低并发性。\n使用乐观锁在更新库存的时候判断一下库存是否大于0，如果库存小于等于0则回滚。\n\n```\nboolean success = seckillVoucherService.update()\n            \t.setSql(\"stock= stock -1\")\n            \t.eq(\"voucher_id\", voucherId).update().gt(\"stock\",0); //where id = ? and stock > 0\n```\n\n\n\n#### 好友共同关注\n\n好友共同关注可以利用Redis中的集合求交集运算来实现。在Redis中保存set集合每一个集合对应一个用户集合里面的内容就是该用户关注用户的用户id这样两个用户求共同关注只需要使用交集运算即可实现。\n\n####  商户缓存功能是怎么做的？\n\n商户缓存通过把商户对象转化为json字符串来保存在redis中，查询商户时，将json字符串转换为商户对象，需要判断商户是否逻辑过期，没过期就直接返回，过期了就会获取一个互斥锁，开启线程缓存重建。\n\n#### 如何解决的一人一单问题？（加分布式锁判断）\n\n利用Redis实现一个分布式锁，synchronized关键字只能再单机的环境下使用，在集群环境下每一台服务器都是一个独立的JVM进程，他们的锁监视器时不共享的，所以不能实现互斥的效果。\n\n解决方法\n\n使用Redisson（提供了许多分布式服务）\n\n- 可重入，同一个线程可多次获取同一把锁，在同一个线程中可能有多个方法获取锁，获取时如果是本线程的锁可以重入（利用hash结构记录线程id和重入次数）\n\n- 可重试 获取锁失败后可重试（获取锁的时候可以设置等待时间，在时间内获取失败可以订阅当前 锁释放的消息， 等锁释放了再尝试获取锁）\n\n- 超时释放：虽然可以避免死锁，但如果是业务执行耗时较长，也会导致锁释放，存在安全隐患，主从一致性（当锁有效期设置为-1，当任务执行时，通过定时任务来动态重置锁的有效期，避免锁超时释放，这就是看门狗机制），在释放锁时，会发送释放锁的消息，取消这个watchDog\n\n  ![image-20231003112419357](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112419357.png)\n\n- 在获取锁方法中，setnx的value需要设置为UUID + 线程ID，在集群环境下可能会存在线程ID相同的问题。这样在删除锁的时候线程需要先根据value值判断是不是自己加的锁，如果不是则说明其他线程已经获取到锁，那么自己执行的业务就应该回滚。如果是自己的锁那么可以直接释放。利用Redis的setnx方法当多个线程进入时只有一个线程能够执行setnx方法返回值为true，其余线程因为key已经存在返回的都是false这就实现互斥。\n- 使用过期时间可以保证出现故障后锁依然可以释放不会产生死锁问题。\n- 利用redis集群来提高可用性。\n- 释放锁的时候需要判断当前的锁是不是自己加的只有当前的锁是自己加的才可以删除。\n\n##### 判断锁和删除锁的动作需要具备原子性因此我们使用了Lua脚本实现多条指令的原子性。\n\n否则如果一个线程已经判断完是自己的锁， 还没有删除的时候突然失去时间片导致锁自动释放。另外一个线程又获取到了锁。那么前一个线程就会释放掉不属于自己的锁。\n\n在这个项目中采用了Lua脚本的方式来保证判断锁和删除锁的原子性。\n\n\n\n####  考虑秒杀过程中Redis宕机的情况？\n\n可以通过建立Redis集群，利用RedLock（红锁）来做分布式锁。RedLock分布式锁的原理简单来说就是你要获取锁，必须获取到集群一半以上的节点而且获取所锁时间没有超过有效时间才算获取锁成功，否则就需要向全部节点发送释放锁的信号。当获得锁后，会重置所有锁的有效期。\n\n如果有节点宕机，就会触发延时重启（ Redis 崩溃后（无论是一个还是所有），先不立即重启它，而是等待 TTL 时间后再重启，它在重启后就不会对现有的锁造成影响），除非全部节点都宕机，否则其他线程还是无法获得锁，不会出现并发问题。\n\n##### RedLock 加锁原理\n\n在 Redis 分布式集群中，假设我们有 5 个 Redis 节点（中小规模项目一般是：1主4从+3哨兵），则 RedLock 加锁过程如下：\n\n- 获取当前Unix时间，以毫秒为单位，并设置锁的超时时间 TTL（TTL 时间要大于 正常业务执行的时间 + 成功获取锁消耗的时间 + 时钟漂移）；\n- 依次从 5 个节点中获取锁，需要使用相同的 key 和具有唯一性的 value。获取锁时，需要设置一个网络连接和响应超时时间，这个超时时间要小于锁的失效时间 TTL，从而避免客户端死等。比如：TTL 为 5s，设置获取锁最多用1s，所以如果一秒内无法获取锁，就放弃获取这个锁，尝试从下个节点获取锁；\n- 客户端获取所有能获取的锁后的时间减去第 1 步的时间，就得到了获取锁消耗的时间（锁的获取时间要小于锁的失效时间 TTL，并且至少从半数以上 (N/2+1)的Redis节点取到锁，才算获取成功锁）；\n- 成功获得锁后，key 的真正有效时间 = TTL - 锁的获取时间 - 时钟漂移。比如：TTL 是10s，获取所有锁用了 2s，则真正锁有效时间为 8s；\n- 如果获取锁失败（没有在半数以上实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的 Redis 实例上进行解锁，即使是没有加锁成功的 Redis 实例；\n- 失败重试：当客户端获取锁失败时，应该在随机时间后重试获取锁；同时重试获取锁要有一定次数限制（在随机时间后进行重试，主要是防止过多的客户端同时尝试去获取锁，导致彼此都获取锁失败的问题）；\n- 加锁失败的实例也要执行解锁操作的原因是：可能会出现服务端响应消息丢失但实际上成功了的情况。\n\n设想这样一种情况：客户端发给某个 Redis 节点的获取锁的请求成功到达了该 Redis 节点，这个节点也成功执行了 SET 操作，但是它返回给客户端的响应包却丢失了。这在客户端看来，获取锁的请求由于超时而失败了，但在Redis这边看来，加锁已经成功了。因此，释放锁的时候，客户端也应该对当时获取锁失败的那些Redis节点同样发起请求。实际上，这种情况在异步通信模型中是有可能发生的：客户端向服务器通信是正常的，但反方向却是有问题的。\n\n##### RedLock 崩溃恢复问题\n\n由于 N 个 Redis 节点中的大多数能正常工作就能保证 Redlock 能正常工作，因此理论上它的可用性更高。所以前面我们说的主从架构下存在的安全性问题，在 RedLock 中已经不存在了。但**如果所有节点同时发生崩溃重启的情况下还是会对锁的安全性有影响**，具体的影响程度跟 Redis 持久化配置有关：\n\n假如我们没有开启 Redis 的持久化功能（比如 AOF），在 ClientA 获取锁成功后，所有 Redis 实例重启后，ClientB 也能够再次获取到锁，这样违法了锁的排他互斥性；\n但实际上我们一般都会启动 AOF 持久化功能，即使如此也会存在一个问题：\n\n但是由于 AOF 同步到磁盘的方式默认是每秒一次，所以如果在一秒内断电，则会导致数据丢失，立即重启后同样会造成锁互斥性的失效；\n但如果同步磁盘方式使用 Always（每一个写命令都同步到硬盘），虽然避免了数据丢失问题，但会造成性能急剧下降，所以需要在锁完全有效性和性能方面进行取舍。\n\n##### 解决方案：\n\n为了有效解决既保证锁完全有效性有保证 Redis 性能高效的问题，Redis 的作者 antirez 提出了 **延迟重启** 的概念：Redis 同步到磁盘方式保持默认的每秒1次，在 Redis 崩溃后（无论是一个还是所有），先不立即重启它，而是等待 TTL 时间后再重启。\n\n这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响，但缺点是在TTL时间内服务相当于暂停状态。但这只是一种参考方案，需要根据实际来判断是否使用。\n\n##### RedLock 的弊端\n\n- 虽然 RedLock 解决 Redis 集群部署下的安全性问题，但同时也牺牲了性能：原来只要主节点写成功了就行了，现在要很多台机器成功加锁才算加锁成功；\n- 当 Redis 全部重启，由于持久化的问题，RedLock 也会存在锁失效的问题，所以 RedLock 并不能100%解决锁失效问题。\n\n\n\n#### redis缓存的数据和数据库的数据，怎么保证一致性？\n\n##### 采用延时双删\n\n先删除缓存，再更新数据库，当更新数据后休眠一段时间通过定时任务（可通过整合定时任务框架、创建线程池，从中拿出一个线程休眠一段时间再启动）再删除一次缓存。\n\n##### 异步更新缓存(基于订阅binlog的同步机制)\n\n采用缓存淘汰策略，先更新数据库，再删除对应redis缓存后更新缓存。\n\n![image-20231003112424781](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112424781.png)\n\n通过 Canal（消息推送工具也可以用kafka、rabbitMQ等来实现可靠性消息通信更新Redis。） 组件，监控 Mysql 中 binlog（记录MySQL中新的写入、更新、删除等操作） 的日志，把更新后的数据同步到 Redis 里面，canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。。\n\n\n\n![image-20231003112435565](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112435565.png)\n\n因为这里是基于最终一致性来实现的，如果业务场景不能接受数据的短期不一致性，那就不能使用这个方案来做。\n\n#### 关于好友点赞和好友关注你是如何实现的\n\n##### 好友点赞\n\n好友点赞的问题应该保证一个好友一个笔记只能点赞一次，而且点赞应该是一个比较频繁的操作，因此考虑使用Redis中的set集合实现这个功能。\n\n在Redis中建立Zset集合，每一个帖子对应一个Zset集合，set集合中保存的数据就是用户点赞的用户id这样在用户点赞的时候就可以先查询一下是否点过赞，如果点过赞则返回已经点赞，否则则将用户id记录到set集合中。Zset的分数就是时间戳，这样就可以根据时间戳的大小实现按照点赞时间排序。\n\n##### 好友关注\n\n关注前会先查询数据库中是否已经有该用户对将关注用户的关注数据，如果有就会回显，变成取消关注，移除数据库中相关关注数据。\n\n如果没有关注过，点击关注就会像数据库插入一条关注数据。\n\n\n\n#### redis中的zset是一个怎样的数据类型？为什么它能根据点赞时间保证数据的有序性？\n\n-  Redis 有序集合（zset）和集合一样也是string类型元素的集合,且不允许重复的成员。\n- 每个元素都会关联一个double类型的分数，redis正是通过分数来为集合中的成员进行从小到大的排序。\n- 集合是通过哈希表实现的。 集合中最大的成员数为 2次方32 - 1 (4294967295, 每个集合可存储40多亿个成员)。\n- 分数就保存点赞时的时间戳，按照时间戳升序排列就可以保证数据有序性。\n\n\n\n#### 点赞排行用MySQL可以吗？专门用Redis保存每一个博客的点赞详情会不会浪费内存？如果像抖音那种一条视频几百万甚至上千万的点赞如果要做点赞排行也用Redis吗？如何优化？\n\n1. 用Redis的Bitmaps数据结构来保存点赞详情。然后从Bitmaps的数据结构角度向面试官阐述如何解决内存占用，这里简单说一下，Bitmaps是以位的形式存储数据，可以有效地压缩存储空间。\n2. 使用redis分片集群，实现分布式存储，将点赞信息分散到多个Redis节点上，减轻单个节点的负载压力。 \n3. 设置合理的过期时间或定期清理过期的点赞数据（因为其实对于一个点赞详细来说，我们应该进行取舍，其实前端页面只需要展示部分数据，要么保存最新的一批点赞详情，要么保存一批最旧的--也就是最先点赞的人），避免占用过多的内存空间，比如说只保存最近三十天的点赞。\n\n##### 使用bitMap来实现点赞的功能\n\n点赞/取消点赞\n假设用户的数字id为1000，对照片id为100的照片点赞。首先根据照片id生成赞数据存储的redis key，比如生成策略为like_photo:{photo_id}，id为1000的用户点赞，只需要将like_photo:100的第1000位置为1即可（取消赞则置为0）。\n\nredis setbit操作的时间复杂度为O(1)，所以这种点赞方式十分高效。\n\n```\nredis.setbit(\"like_photo:100\", 1000, 1);\n```\n\n\n当前是否点赞\n用户打开图片的时候需要查询当前是否点赞过该照片，查询是否点赞可以通过redis getbit操作来实现。比如查询用户id为1000的用户是否点赞过照片id为100的照片，只需要对like_photo:100bitmap的第1000位取值即可。\n\nredis getbit操作的时间复杂度同样是O(1)。\n\n```\nredis.getbit(\"like_photo:100\", 1000);\n```\n\n\n查询点赞总次数\n比如需要显示照片id为100的照片的获赞次数，只需要对like_photo:100bitmap进行位图计数操作即可。\n\nredis bitcount操作的时间复杂度虽然是O(N)的，但是大部分数据量的情况下是不需要担心bitcount效率问题的\n\n```\nredis.bitcount(\"like_photo:100\");\n```\n\n当用户量很大的时候，比如千万级用户量的情况下，一个用户的bitmap需要消耗的内存为：10000000/8/1024/1024=1.19MB，当bitmap数量较多的时候，内存占用还是很可观的。不过在用户量较少的时候这种方案还是不错的\n\n\n\n#### 取消订单的逻辑\n\n我的项目并没有取消订单这个功能，如果让我来设计的话，我会先查询数据库中的订单表中优惠券的id，通过CAS对相应的优惠券库存+1，成功后把这个订单设置为逻辑过期。\n\n#### 拦截器过滤器的作用\n\n![image-20231003112444100](Java%E5%85%AB%E8%82%A1%E8%87%AA%E6%80%BB%E7%BB%93%EF%BC%9A.assets/image-20231003112444100.png)\n\n1. 运行顺序不同（如图）：过滤器是在 Servlet 容器接收到请求之后，但在 Servlet被调用之前运行的；而拦截器则是在 Servlet 被调用之后，但在响应被发送到客户端之前运行的。\n2. 配置方式不同：过滤器是在 web.xml 中进行配置；而拦截器的配置则是在 Spring的配置文件中进行配置，或者使用注解进行配置。\n3. Filter 依赖于 Servlet 容器，而 Interceptor 不依赖于 Servlet 容器\n4. Filter 在过滤是只能对 request 和 response 进行操作，而 interceptor 可以对request、response、handler、modelAndView、exception 进行操作。\n\n#### 有没有压力测试？\n\n通过Jmeter测试了秒杀和一人一单业务是否存在并发问题，然后还测试了将商户信息、点赞等热点信息加入缓存后的QPS提升\n\n## 业务问题\n\n#### 线上oom怎么处理\n\n#### 可能会产生OOM的区域，以及各种区域产生OOM的原因\n\n#### 栈溢出的可能原因\n\n## HR面\n\n#### 为啥选择Java？\n\n- Java略去了指针，实现了自动垃圾回收，相对简单易学，而且学习资料很多。\n- Java有很多优秀的框架和类库，可以大大提高开发效率，简化开发\n- Java岗位相对较多，市场需求广泛。\n\n#### 在校期间做过什么项目？扮演什么角色？\n\n#### 了解用友吗？\n\n#### 为什么选择用友？\n\n开放进取，诚信担当。\n\n1. **公司文化和价值观的契合：** 强调你对公司文化和价值观的共鸣。说明你认为公司的文化与你的职业理念相符，这将有助于你更好地融入公司并有更大的工作满意度。\n2. **公司的声誉和历史：** 提到你对公司的声誉和历史有所了解，以及对公司在行业中的地位有一定认知。你可以分享你对公司成功案例或行业奖项的印象。\n3. **对工作职责的兴趣：** 强调你对所申请职位的兴趣和热情。描述你如何认为自己的技能和经验与职位要求相匹配，以及你渴望为公司的团队做出贡献。\n4. **发展机会：** 谈论你对公司内部发展机会的期望。你可以提到你希望在公司内部不断学习和成长，并且看到自己在未来有机会晋升或扩展职业领域。\n\n#### 手里有其他offer吗？\n\n#### 薪资期望多少？\n\n#### 如果同事们的风格和自己十分格格不入怎么办\n\n1. **尊重和沟通：** 首先，尊重每个人的不同风格和观点。尝试建立积极的沟通，并听取同事的看法和意见。问他们是否有特殊需求或期望，以了解他们的立场。\n2. **倾听技巧：** 提高自己的倾听技巧，确保你真正理解同事的立场和需求。主动询问问题并表达关切，以建立更好的互动。\n3. **建立共识：** 在困难情况下，试图找到共识和妥协点。了解到底有哪些问题导致了不和谐，然后尝试找到解决方案，以满足双方的需求。\n4. **寻找中立的第三方：** 如果有争议或纠纷，考虑寻找一个中立的第三方，例如上级或HR，来协助解决问题。他们可以提供中立的建议和指导。\n5. **冷静反思：** 对于自己和同事的争议，进行冷静的反思。思考是否有什么可以改进的地方，以及如何更好地处理类似的情况。\n\n#### 怎么看待加班文化\n\n1. **强调工作效率和时间管理**： 努力在正常工作时间内完成任务。你可以提到你的时间管理技能，如使用任务列表、优先级制定等方法，以确保任务按时完成。\n2. **灵活性：** 表明你愿意在必要时加班，以确保项目的顺利进行。强调你的灵活性和适应能力，但也强调这不应该成为常态，而是在特定情况下的例外。\n3. **平衡工作和生活：** 重申你重视工作与生活的平衡。指出长期加班可能会导致疲劳、降低工作质量和员工满意度下降。你认为公司应该鼓励员工保持平衡，从而提高工作效率和员工幸福感。\n\n#### 最后反问\n\n\n\n## 算法\n\n#### LRU 算法，什么原理，怎么实现\n\n#### 迭代遍历二叉树\n\n\n\n#### 手写堆排序\n\n```\nimport java.util.Arrays;\nimport java.util.SortedMap;\n\npublic class heapSort {\n\n    public static void main(String[] args) {\n        int[] target = new int[]{1,3,2,7,4,5,10,9,9,8};\n        heapSort heap = new heapSort();\n        int[] nums = heap.sort(target);\n        for(int num : nums) {\n            System.out.println(num + \" \");\n        }\n\n    }\n    \n    public  int[] sort(int[] sourceArray) {\n        int arr[] = Arrays.copyOf(sourceArray, sourceArray.length);\n        int len = arr.length;\n        buildMaxHeap(arr, len);//建立好大根堆，每次将最大值与最后一个数交换位置，并从根节点开始调整大根堆\n        for(int i = len - 1; i > 0; i--) {\n            swap(arr, 0, i);\n            len--;\n            heapify(arr, 0, len);\n        }\n        return arr;\n    }\n\n    private void heapify(int[] arr, int i, int len) {\n        int left = 2 * i + 1;\n        int right = 2 * i + 2;\n        int largest = i;\n        if (left < len && arr[left] > arr[largest]) {\n            largest = left;\n        }\n        if (right < len && arr[right] > arr[largest]) {\n            largest = right;\n        }\n\n        if (largest != i) {\n            swap(arr, i, largest);\n            heapify(arr, largest, len);\n        }\n\n    }\n\n    private void buildMaxHeap(int[] arr, int len) {//通过这个函数，从最后一个非叶子节点开始向上，逐渐建立一颗大根堆的树\n        for(int i = len / 2 - 1; i >= 0; i--) {\n            heapify(arr, i, len);\n        }\n    }\n    private void swap(int[] arr, int i, int j) {\n        int temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n    }\n}\n```\n\n"},{"title":"Hello World","url":"/2023/10/03/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]